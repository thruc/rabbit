{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "3_1_simple_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cNl2QA_Rnv5"
      },
      "source": [
        "# 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkwjN1jNVAYy"
      },
      "source": [
        "## Googleドライブのマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvFXpiH3EVC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc8a4ac-45c5-4c24-de73-20e8c76648cf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ub7RYdeY6pK"
      },
      "source": [
        "## sys.pathの設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oql7L19rEsWi"
      },
      "source": [
        "以下では，Googleドライブのマイドライブ直下にDNN_codeフォルダを置くことを仮定しています．必要に応じて，パスを変更してください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ic2JzkvFX59"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/DNN_code')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feXB1SiLP4OL"
      },
      "source": [
        "# simple RNN\n",
        "### バイナリ加算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tzSWNYwxP4OM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82288448-4e84-4c5e-b618-269d687747ca"
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# def d_tanh(x):\n",
        "\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 8\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# Xavier\n",
        "\n",
        "\n",
        "# He\n",
        "\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "\n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Loss:1.592313958307537\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 0 0 0 0]\n",
            "23 + 25 = 255\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.120778481405919\n",
            "Pred:[0 0 0 1 0 0 0 1]\n",
            "True:[0 0 0 0 1 1 1 0]\n",
            "6 + 8 = 17\n",
            "------------\n",
            "iters:200\n",
            "Loss:0.8984035840821232\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "34 + 45 = 223\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.0003793688497242\n",
            "Pred:[1 0 1 0 0 1 0 1]\n",
            "True:[1 1 0 1 0 1 0 0]\n",
            "90 + 122 = 165\n",
            "------------\n",
            "iters:400\n",
            "Loss:0.9763430757616574\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 1 1 0 0 1 0]\n",
            "71 + 107 = 158\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.0280648099146508\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 0 0 1 0]\n",
            "124 + 54 = 0\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.01957088943565\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 0 1 0 1 0]\n",
            "127 + 75 = 255\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.0087138672215865\n",
            "Pred:[0 0 0 0 1 0 1 0]\n",
            "True:[1 0 1 1 1 0 0 1]\n",
            "77 + 108 = 10\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.9343029958627398\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "117 + 66 = 254\n",
            "------------\n",
            "iters:900\n",
            "Loss:1.0075841314875384\n",
            "Pred:[0 1 0 0 0 0 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "104 + 67 = 67\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.0120241396856733\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "0 + 78 = 0\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.9456664793305752\n",
            "Pred:[0 0 0 0 1 1 1 0]\n",
            "True:[0 0 1 1 0 1 1 0]\n",
            "7 + 47 = 14\n",
            "------------\n",
            "iters:1200\n",
            "Loss:1.0859943327030044\n",
            "Pred:[0 0 0 0 1 0 1 0]\n",
            "True:[1 0 1 1 0 0 0 1]\n",
            "69 + 108 = 10\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.9469231434330707\n",
            "Pred:[0 0 0 0 0 1 1 0]\n",
            "True:[1 1 0 0 0 0 1 0]\n",
            "107 + 87 = 6\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.9443152848674631\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "53 + 27 = 2\n",
            "------------\n",
            "iters:1500\n",
            "Loss:1.0337091480846392\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "16 + 47 = 0\n",
            "------------\n",
            "iters:1600\n",
            "Loss:1.0112502349940609\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "66 + 118 = 4\n",
            "------------\n",
            "iters:1700\n",
            "Loss:1.0063685631170654\n",
            "Pred:[1 0 0 0 0 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "99 + 27 = 134\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.7959830758916014\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 0 0 1 0 0]\n",
            "16 + 20 = 0\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.9585839221276636\n",
            "Pred:[1 1 1 1 0 1 1 1]\n",
            "True:[1 1 0 1 0 0 1 0]\n",
            "98 + 112 = 247\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.8735005338858013\n",
            "Pred:[0 0 0 0 1 1 0 0]\n",
            "True:[0 0 0 1 1 1 0 0]\n",
            "22 + 6 = 12\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.985720235460408\n",
            "Pred:[1 0 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "94 + 24 = 188\n",
            "------------\n",
            "iters:2200\n",
            "Loss:1.0678883051572576\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 1 0 0 0 1 1 0]\n",
            "9 + 61 = 63\n",
            "------------\n",
            "iters:2300\n",
            "Loss:1.1215967023751203\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "31 + 65 = 127\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.9803147938166066\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 0 1 0 1 1]\n",
            "79 + 124 = 255\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.9928213772552883\n",
            "Pred:[1 1 1 1 1 0 1 1]\n",
            "True:[1 0 1 1 1 1 0 1]\n",
            "89 + 100 = 251\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.8545001045854205\n",
            "Pred:[1 0 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "85 + 90 = 191\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.8410559511451252\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "64 + 88 = 0\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.923404071187964\n",
            "Pred:[0 0 1 1 0 0 1 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "25 + 27 = 50\n",
            "------------\n",
            "iters:2900\n",
            "Loss:1.1133816150663312\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[1 0 1 1 1 1 0 0]\n",
            "123 + 65 = 2\n",
            "------------\n",
            "iters:3000\n",
            "Loss:1.0412506562946793\n",
            "Pred:[0 0 1 1 1 1 0 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "14 + 54 = 60\n",
            "------------\n",
            "iters:3100\n",
            "Loss:1.0775263327974947\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "94 + 47 = 126\n",
            "------------\n",
            "iters:3200\n",
            "Loss:1.0158266867063213\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[1 0 1 0 1 0 0 1]\n",
            "60 + 109 = 88\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.8952837748142638\n",
            "Pred:[0 1 0 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "47 + 78 = 95\n",
            "------------\n",
            "iters:3400\n",
            "Loss:1.1306554278395338\n",
            "Pred:[0 0 0 1 1 1 1 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "90 + 7 = 31\n",
            "------------\n",
            "iters:3500\n",
            "Loss:1.0207265859745638\n",
            "Pred:[0 1 0 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "103 + 5 = 79\n",
            "------------\n",
            "iters:3600\n",
            "Loss:1.1220541848444507\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 1 1 0 0 0]\n",
            "127 + 89 = 255\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.9761781346107838\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "48 + 125 = 127\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.7664284855957492\n",
            "Pred:[0 1 0 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "89 + 6 = 95\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.9346550603230107\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "66 + 54 = 100\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.9212671639102007\n",
            "Pred:[0 1 0 1 1 0 1 1]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "57 + 35 = 91\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.6661623215828638\n",
            "Pred:[0 0 1 0 1 1 0 0]\n",
            "True:[0 0 1 0 1 1 1 0]\n",
            "28 + 18 = 44\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.999955071386551\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "105 + 4 = 255\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.9735013222305039\n",
            "Pred:[1 1 0 1 0 1 1 1]\n",
            "True:[1 1 1 0 0 1 1 1]\n",
            "124 + 107 = 215\n",
            "------------\n",
            "iters:4400\n",
            "Loss:1.020350501203136\n",
            "Pred:[1 1 1 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "60 + 93 = 251\n",
            "------------\n",
            "iters:4500\n",
            "Loss:1.0141220825376716\n",
            "Pred:[1 0 1 0 1 1 0 0]\n",
            "True:[1 1 0 1 0 1 0 0]\n",
            "118 + 94 = 172\n",
            "------------\n",
            "iters:4600\n",
            "Loss:1.0650997264728677\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "90 + 41 = 115\n",
            "------------\n",
            "iters:4700\n",
            "Loss:1.064178282154741\n",
            "Pred:[1 1 1 0 1 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "62 + 86 = 236\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.6634577335418512\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "68 + 83 = 151\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.6440161166638709\n",
            "Pred:[1 0 1 0 1 1 1 1]\n",
            "True:[1 1 1 0 1 1 1 1]\n",
            "123 + 116 = 175\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.7423264526037056\n",
            "Pred:[1 0 1 1 1 1 1 1]\n",
            "True:[1 0 1 1 1 1 1 1]\n",
            "82 + 109 = 191\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.760104950689228\n",
            "Pred:[1 0 1 1 0 1 1 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "61 + 89 = 182\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.41301602323942965\n",
            "Pred:[1 1 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "96 + 34 = 194\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.770923571132379\n",
            "Pred:[1 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "40 + 81 = 249\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.6458411198146382\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 1 0 1 1]\n",
            "25 + 34 = 127\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.4976466769446628\n",
            "Pred:[0 1 0 1 0 1 1 1]\n",
            "True:[0 1 0 1 0 1 0 1]\n",
            "85 + 0 = 87\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.5707152497192863\n",
            "Pred:[0 0 1 1 1 1 0 1]\n",
            "True:[0 0 1 1 0 1 0 1]\n",
            "15 + 38 = 61\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.7290262834754256\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "5 + 58 = 117\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.7780961313090748\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "61 + 36 = 123\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.597630785050435\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 1 0 0 0 1 1 1]\n",
            "96 + 103 = 135\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.5327950781179902\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "102 + 56 = 158\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.4378025236720537\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "15 + 37 = 52\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.14701352430180212\n",
            "Pred:[0 0 0 1 0 1 1 0]\n",
            "True:[0 0 0 1 0 1 1 0]\n",
            "12 + 10 = 22\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.5785303178782871\n",
            "Pred:[1 1 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "20 + 117 = 201\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.4108914808216387\n",
            "Pred:[1 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "121 + 1 = 250\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.4192970934287581\n",
            "Pred:[1 0 1 0 0 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "72 + 95 = 167\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.4872390238262926\n",
            "Pred:[1 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "72 + 52 = 252\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.357864281507031\n",
            "Pred:[1 0 1 1 1 1 0 1]\n",
            "True:[1 0 1 1 1 1 0 1]\n",
            "126 + 63 = 189\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.06146128845093843\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "3 + 91 = 94\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.14920694136438095\n",
            "Pred:[0 1 0 0 1 0 1 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "51 + 23 = 74\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.14554048082775223\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "3 + 118 = 121\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.0485584582913216\n",
            "Pred:[0 0 0 1 1 1 0 0]\n",
            "True:[0 0 0 1 1 1 0 0]\n",
            "3 + 25 = 28\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.11008603399738305\n",
            "Pred:[1 0 0 0 1 0 0 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "101 + 35 = 136\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.11285438731054438\n",
            "Pred:[0 0 0 0 1 1 1 1]\n",
            "True:[0 0 0 0 1 1 1 1]\n",
            "7 + 8 = 15\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.04523095292827958\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "42 + 36 = 78\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.07141246778295286\n",
            "Pred:[1 0 0 1 1 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "123 + 31 = 154\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.13784227696074386\n",
            "Pred:[0 1 0 1 1 0 1 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "28 + 63 = 91\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.03651015122876109\n",
            "Pred:[0 0 1 0 1 1 0 0]\n",
            "True:[0 0 1 0 1 1 0 0]\n",
            "28 + 16 = 44\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.09527120259923696\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "90 + 54 = 144\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.008833760198127205\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "35 + 33 = 68\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.02932964552734183\n",
            "Pred:[0 0 1 1 1 0 0 1]\n",
            "True:[0 0 1 1 1 0 0 1]\n",
            "6 + 51 = 57\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.06773344495875083\n",
            "Pred:[1 0 1 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "81 + 79 = 160\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.024615203160696025\n",
            "Pred:[1 0 1 0 0 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "99 + 68 = 167\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.039691394489418545\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "118 + 41 = 159\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.04028311504486983\n",
            "Pred:[0 1 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "58 + 54 = 112\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.009839532051212706\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "25 + 31 = 56\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.014575880044459507\n",
            "Pred:[0 1 0 0 0 0 0 1]\n",
            "True:[0 1 0 0 0 0 0 1]\n",
            "60 + 5 = 65\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.02459637206435234\n",
            "Pred:[1 1 1 0 0 0 1 0]\n",
            "True:[1 1 1 0 0 0 1 0]\n",
            "108 + 118 = 226\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.021628611312923696\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "47 + 112 = 159\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.022051803110337897\n",
            "Pred:[1 1 0 0 0 1 0 0]\n",
            "True:[1 1 0 0 0 1 0 0]\n",
            "106 + 90 = 196\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.004214474870207899\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "13 + 39 = 52\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.019618805074100965\n",
            "Pred:[1 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "48 + 95 = 143\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.015875648216170626\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "62 + 89 = 151\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.012541629852487409\n",
            "Pred:[1 1 1 0 1 1 1 1]\n",
            "True:[1 1 1 0 1 1 1 1]\n",
            "123 + 116 = 239\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.01349386807841235\n",
            "Pred:[1 0 0 0 0 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "18 + 113 = 131\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.01186528563058282\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "118 + 5 = 123\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.002026379274429483\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "31 + 21 = 52\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.004822478196341126\n",
            "Pred:[1 1 0 0 0 0 1 1]\n",
            "True:[1 1 0 0 0 0 1 1]\n",
            "81 + 114 = 195\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.004734189418094821\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "85 + 56 = 141\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.015046097271705926\n",
            "Pred:[1 0 1 1 1 0 1 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "60 + 126 = 186\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7zQEPrtP4OP"
      },
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "## [try] weight_init_stdやlearning_rate, hidden_layer_sizeを変更してみよう\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rD_J7oZGJe5l",
        "outputId": "015a7b53-ee5c-4de4-e4ae-73a8f339288a"
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# def d_tanh(x):\n",
        "\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 32\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.05\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# Xavier\n",
        "\n",
        "\n",
        "# He\n",
        "\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "\n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Loss:1.303256851078019\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "110 + 21 = 0\n",
            "------------\n",
            "iters:100\n",
            "Loss:0.7772971628473239\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[0 0 1 0 1 1 1 1]\n",
            "11 + 36 = 43\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.20852237742954\n",
            "Pred:[0 0 0 0 0 1 0 1]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "7 + 107 = 5\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.3971190217087737\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "125 + 37 = 255\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.0350607319943388\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 1 1 0 0 0 1 1]\n",
            "117 + 110 = 254\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.162776096728742\n",
            "Pred:[0 0 0 1 1 1 1 1]\n",
            "True:[0 0 1 0 0 0 0 1]\n",
            "31 + 2 = 31\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.9156973172195932\n",
            "Pred:[0 0 1 0 1 0 0 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "30 + 60 = 40\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.8988378085527498\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "86 + 57 = 255\n",
            "------------\n",
            "iters:800\n",
            "Loss:1.0318542371280006\n",
            "Pred:[0 0 0 0 1 1 1 1]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "39 + 13 = 15\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.8995239345626905\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 1 0 0 1 1 1 0]\n",
            "102 + 104 = 140\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.9176444562605756\n",
            "Pred:[0 1 0 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "55 + 53 = 73\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.8973377761563822\n",
            "Pred:[0 0 0 1 0 1 1 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "31 + 72 = 23\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.8832899217428842\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 0 0 1 1 1 0 0]\n",
            "9 + 19 = 63\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.799153214111177\n",
            "Pred:[0 0 1 1 1 1 0 0]\n",
            "True:[0 0 1 1 0 0 0 0]\n",
            "26 + 22 = 60\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.8186534294892795\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "78 + 84 = 168\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.5889392493009659\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 0 0 1 0 0]\n",
            "4 + 32 = 0\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.7060257229431551\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 0 1 1 1 1 0 0]\n",
            "46 + 14 = 124\n",
            "------------\n",
            "iters:1700\n",
            "Loss:1.0308818999292446\n",
            "Pred:[1 1 0 1 0 0 1 0]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "101 + 42 = 210\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.858761259131517\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "59 + 43 = 66\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.6574518494968309\n",
            "Pred:[0 0 0 1 1 0 1 1]\n",
            "True:[0 0 0 1 0 0 0 1]\n",
            "7 + 10 = 27\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.8811980106189732\n",
            "Pred:[0 1 0 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "18 + 107 = 91\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.6991659680921458\n",
            "Pred:[0 1 1 1 1 1 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "37 + 72 = 125\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.8841467740672107\n",
            "Pred:[1 0 1 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "8 + 87 = 191\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.6835717518304777\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "73 + 80 = 145\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.6239403200891521\n",
            "Pred:[1 0 1 0 1 0 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "102 + 68 = 170\n",
            "------------\n",
            "iters:2500\n",
            "Loss:1.0975257818115498\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "35 + 111 = 255\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.6048585429708304\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "85 + 33 = 126\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.45087873477709395\n",
            "Pred:[0 0 1 1 1 1 1 0]\n",
            "True:[0 0 1 1 1 0 1 0]\n",
            "52 + 6 = 62\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.7091970667253499\n",
            "Pred:[1 1 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "41 + 110 = 215\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.7520144190190259\n",
            "Pred:[0 1 1 0 1 1 0 1]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "58 + 15 = 109\n",
            "------------\n",
            "iters:3000\n",
            "Loss:1.1197619731223003\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "47 + 25 = 103\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.38261810729670614\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "80 + 8 = 88\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.5383590185694463\n",
            "Pred:[0 1 0 0 0 1 0 1]\n",
            "True:[0 1 0 0 0 1 0 1]\n",
            "26 + 43 = 69\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.8539444190150349\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "57 + 95 = 132\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.17379280280074935\n",
            "Pred:[0 0 1 0 0 0 1 0]\n",
            "True:[0 0 1 0 0 0 1 0]\n",
            "34 + 0 = 34\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.49820918306344575\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "92 + 11 = 103\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.5080630014552067\n",
            "Pred:[0 0 1 1 0 1 1 0]\n",
            "True:[0 0 1 1 0 1 1 0]\n",
            "11 + 43 = 54\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.24440157502166193\n",
            "Pred:[0 0 1 0 1 0 1 0]\n",
            "True:[0 0 1 0 1 0 1 0]\n",
            "24 + 18 = 42\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.772701582099069\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "22 + 106 = 168\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.6405692852115629\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 1 0 0 0 0 1 0]\n",
            "80 + 114 = 162\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.8503543140995746\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 1 0 0 0 1 1 0]\n",
            "111 + 87 = 146\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.3567612450941897\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "48 + 48 = 64\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.3799798099733066\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "68 + 46 = 122\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.21194734398484616\n",
            "Pred:[0 0 0 0 1 1 1 0]\n",
            "True:[0 0 0 0 1 1 1 0]\n",
            "13 + 1 = 14\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.37378634910309594\n",
            "Pred:[0 0 1 1 1 1 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "5 + 51 = 60\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.4330514010237732\n",
            "Pred:[0 0 1 0 0 0 0 1]\n",
            "True:[0 0 1 0 0 0 0 1]\n",
            "2 + 31 = 33\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.23128324218335317\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "3 + 104 = 107\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.2997045093292271\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[0 0 1 0 1 0 0 1]\n",
            "19 + 22 = 43\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.49058065271233015\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "44 + 59 = 111\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.2838346096415873\n",
            "Pred:[1 0 0 1 0 1 1 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "37 + 113 = 150\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.3766869953852756\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "18 + 114 = 132\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.19783421001261006\n",
            "Pred:[0 0 1 0 0 0 1 0]\n",
            "True:[0 0 1 0 0 0 1 0]\n",
            "20 + 14 = 34\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.5340187309506876\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 1 0 1 0 1 1 1]\n",
            "111 + 104 = 151\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.1125748912563853\n",
            "Pred:[0 0 1 1 1 0 1 1]\n",
            "True:[0 0 1 1 1 0 1 1]\n",
            "50 + 9 = 59\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.19253043642587073\n",
            "Pred:[1 1 0 0 1 1 1 0]\n",
            "True:[1 1 0 0 1 1 1 0]\n",
            "118 + 88 = 206\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.05258695343350648\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "66 + 52 = 118\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.09072662512330987\n",
            "Pred:[1 0 1 1 1 0 1 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "68 + 118 = 186\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.256755493262461\n",
            "Pred:[1 1 0 1 1 0 1 0]\n",
            "True:[1 1 0 1 1 0 1 0]\n",
            "124 + 94 = 218\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.08734250753949609\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "45 + 81 = 126\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.041609938797455504\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "28 + 66 = 94\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.292177505369244\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "5 + 63 = 68\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.1679235544151212\n",
            "Pred:[0 1 0 1 1 1 0 0]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "9 + 83 = 92\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.19255000058694255\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "46 + 25 = 71\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.3190896318748384\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "127 + 5 = 132\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.14135596670224085\n",
            "Pred:[1 0 0 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "51 + 104 = 155\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.06189671292979759\n",
            "Pred:[0 0 1 0 1 0 0 0]\n",
            "True:[0 0 1 0 1 0 0 0]\n",
            "6 + 34 = 40\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.15437103421589882\n",
            "Pred:[1 0 1 0 1 0 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "93 + 77 = 170\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.06907917521165632\n",
            "Pred:[0 0 0 0 1 0 1 1]\n",
            "True:[0 0 0 0 1 0 1 1]\n",
            "8 + 3 = 11\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.03373655942829917\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "16 + 86 = 102\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.12111444981557197\n",
            "Pred:[1 0 0 1 1 0 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "60 + 93 = 153\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.1791220328704658\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "119 + 39 = 158\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.057967220103840984\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "83 + 36 = 119\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.08158167929097256\n",
            "Pred:[1 1 0 0 0 1 1 1]\n",
            "True:[1 1 0 0 0 1 1 1]\n",
            "116 + 83 = 199\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.1873490530479527\n",
            "Pred:[1 1 1 1 1 0 1 0]\n",
            "True:[1 1 1 1 1 0 1 0]\n",
            "125 + 125 = 250\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.09609117667624585\n",
            "Pred:[0 1 0 0 1 0 1 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "7 + 67 = 74\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.06349028808518978\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "53 + 77 = 130\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.12615232837793125\n",
            "Pred:[1 0 1 1 1 0 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "103 + 81 = 184\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.22696175465269058\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "25 + 55 = 80\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.08501605406587454\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "63 + 103 = 166\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.08867135498365344\n",
            "Pred:[1 0 1 1 0 1 1 0]\n",
            "True:[1 0 1 1 0 1 1 0]\n",
            "122 + 60 = 182\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.09513683751738403\n",
            "Pred:[1 0 1 0 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "79 + 95 = 174\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.019625572573003753\n",
            "Pred:[0 0 0 1 1 0 1 0]\n",
            "True:[0 0 0 1 1 0 1 0]\n",
            "8 + 18 = 26\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.026180000518482367\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "126 + 32 = 158\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.0858978439007488\n",
            "Pred:[0 1 0 1 1 1 0 1]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "27 + 66 = 93\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.04544543457426169\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "93 + 36 = 129\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.038994676801003485\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "86 + 21 = 107\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.06295244567395598\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "27 + 92 = 119\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.058626915013940135\n",
            "Pred:[1 0 0 0 0 1 1 0]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "115 + 19 = 134\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.014443974631804007\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "100 + 52 = 152\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.06865380057250207\n",
            "Pred:[0 1 0 1 0 1 0 1]\n",
            "True:[0 1 0 1 0 1 0 1]\n",
            "7 + 78 = 85\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.04159485496858606\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "82 + 91 = 173\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.030910697522141123\n",
            "Pred:[1 0 1 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "95 + 65 = 160\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.029196600159175037\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "12 + 109 = 121\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.022890860622601306\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "126 + 20 = 146\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.016958975817409305\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "46 + 20 = 66\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.02742916900684931\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "51 + 12 = 63\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.019164242172059108\n",
            "Pred:[0 0 1 1 0 0 0 1]\n",
            "True:[0 0 1 1 0 0 0 1]\n",
            "49 + 0 = 49\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.02356021204870553\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "52 + 19 = 71\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.022030515677388052\n",
            "Pred:[0 0 1 1 1 0 1 1]\n",
            "True:[0 0 1 1 1 0 1 1]\n",
            "20 + 39 = 59\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.025016315645375216\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "28 + 107 = 135\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i3-mL38TJcUh",
        "outputId": "83bda160-8d71-41f3-847f-19d798a946fb"
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# def d_tanh(x):\n",
        "\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# Xavier\n",
        "\n",
        "\n",
        "# He\n",
        "\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "\n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Loss:2.174293770836696\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 0 1 1 0]\n",
            "74 + 108 = 0\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.0064718047007344\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "44 + 70 = 68\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.1020839127055944\n",
            "Pred:[0 0 0 1 1 1 0 1]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "77 + 29 = 29\n",
            "------------\n",
            "iters:300\n",
            "Loss:0.9975968950756293\n",
            "Pred:[0 0 0 1 0 1 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "9 + 88 = 21\n",
            "------------\n",
            "iters:400\n",
            "Loss:0.9286502657458573\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "67 + 89 = 151\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.9182445301868937\n",
            "Pred:[1 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "55 + 68 = 239\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.8719683401579325\n",
            "Pred:[1 1 0 0 0 1 1 0]\n",
            "True:[1 1 0 1 1 1 1 1]\n",
            "123 + 100 = 198\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.9484808314456157\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "22 + 74 = 4\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.8343317803447365\n",
            "Pred:[1 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "82 + 34 = 228\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.9024645847050567\n",
            "Pred:[1 1 0 1 0 1 1 1]\n",
            "True:[1 1 1 0 0 0 1 1]\n",
            "106 + 121 = 215\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.9584674823600303\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "113 + 30 = 255\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.1352007198204055\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 1 1 0 1 0 0]\n",
            "103 + 77 = 138\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.9139321330853184\n",
            "Pred:[0 1 1 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "28 + 98 = 96\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.7723681570304093\n",
            "Pred:[0 0 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "67 + 9 = 14\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.5836184665692289\n",
            "Pred:[0 1 0 1 0 1 0 1]\n",
            "True:[0 1 0 1 0 1 0 1]\n",
            "1 + 84 = 85\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.711366727526251\n",
            "Pred:[1 0 1 1 0 0 0 0]\n",
            "True:[1 1 0 0 0 0 0 0]\n",
            "88 + 104 = 176\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.7583375361335482\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "81 + 74 = 159\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.8186319548996643\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 1 0 0 0 1]\n",
            "87 + 90 = 173\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.6293304644965249\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "8 + 66 = 0\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.6699437115390173\n",
            "Pred:[0 1 0 0 1 1 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "2 + 102 = 76\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.324460269495577\n",
            "Pred:[0 0 1 0 0 1 1 0]\n",
            "True:[0 0 1 0 0 1 1 0]\n",
            "37 + 1 = 38\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.8024346455987642\n",
            "Pred:[1 1 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "15 + 111 = 240\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.7353467982066876\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "85 + 30 = 107\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.8746357656232191\n",
            "Pred:[1 1 0 1 0 0 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "62 + 109 = 211\n",
            "------------\n",
            "iters:2400\n",
            "Loss:1.0929492061923756\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 1 0 1 0 0 0 0]\n",
            "122 + 86 = 140\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.43997005986010934\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "84 + 27 = 111\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.8718620816121262\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "94 + 115 = 129\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.6368497601766109\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "111 + 22 = 129\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.9026777351500893\n",
            "Pred:[0 0 1 0 0 1 1 1]\n",
            "True:[0 0 0 1 1 1 1 1]\n",
            "31 + 0 = 39\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.39019491806152684\n",
            "Pred:[1 0 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "109 + 49 = 156\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.20144975093191061\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "114 + 44 = 158\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.08862810684273287\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "36 + 16 = 52\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.754627362689589\n",
            "Pred:[1 0 1 0 0 0 0 1]\n",
            "True:[1 1 0 1 1 0 0 1]\n",
            "93 + 124 = 161\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.45558074123666487\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "30 + 44 = 66\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.46854668059635446\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 1 0 0 0 0 1 0]\n",
            "120 + 74 = 130\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.6187106398734384\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "39 + 47 = 80\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.8670832963311136\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "19 + 61 = 108\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.3559866821204679\n",
            "Pred:[0 1 0 0 1 1 1 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "26 + 53 = 79\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.2256172680911125\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "78 + 37 = 115\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.47403582569880254\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "119 + 49 = 168\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.21929357073912056\n",
            "Pred:[0 0 0 1 0 0 1 1]\n",
            "True:[0 0 0 1 0 0 1 1]\n",
            "7 + 12 = 19\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.07682163362243953\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "17 + 88 = 105\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.1462525697586703\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "77 + 25 = 102\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.37363511614347955\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "46 + 26 = 64\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.44538346387355787\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "91 + 23 = 114\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.2925922849096355\n",
            "Pred:[1 0 0 1 0 0 1 1]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "63 + 84 = 147\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.04169189751956657\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "100 + 66 = 166\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.07548851032098007\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "65 + 70 = 135\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.28648892278979443\n",
            "Pred:[1 1 0 0 0 1 1 1]\n",
            "True:[1 1 0 0 0 1 1 1]\n",
            "86 + 113 = 199\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.2503757771500413\n",
            "Pred:[1 1 1 0 0 1 1 1]\n",
            "True:[1 1 1 0 0 1 1 1]\n",
            "105 + 126 = 231\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.11074434785304352\n",
            "Pred:[0 1 0 0 0 0 1 1]\n",
            "True:[0 1 0 0 0 0 1 1]\n",
            "48 + 19 = 67\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.12485101697192626\n",
            "Pred:[1 1 0 0 1 0 0 1]\n",
            "True:[1 1 0 0 1 0 0 1]\n",
            "113 + 88 = 201\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.06829594957956384\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "44 + 83 = 127\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.12825604046979894\n",
            "Pred:[0 1 1 1 1 1 0 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "15 + 110 = 125\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.20014525040576975\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "87 + 26 = 113\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.19891928712516413\n",
            "Pred:[1 1 0 1 0 1 1 1]\n",
            "True:[1 1 0 1 0 1 1 1]\n",
            "95 + 120 = 215\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.042626392970007435\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "113 + 4 = 117\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.09950475923665233\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "12 + 116 = 128\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.09506444021252061\n",
            "Pred:[1 0 0 1 1 1 0 1]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "118 + 39 = 157\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.04098141489165135\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "97 + 22 = 119\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.06824319900713187\n",
            "Pred:[1 1 1 1 0 0 1 0]\n",
            "True:[1 1 1 1 0 0 1 0]\n",
            "126 + 116 = 242\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.03934876929301776\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "3 + 114 = 117\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.039699792427329086\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "65 + 84 = 149\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.07379106986728033\n",
            "Pred:[1 1 1 0 1 1 0 1]\n",
            "True:[1 1 1 0 1 1 0 1]\n",
            "118 + 119 = 237\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.023662963221910995\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "40 + 86 = 126\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.03858057713565597\n",
            "Pred:[0 0 0 0 0 1 1 1]\n",
            "True:[0 0 0 0 0 1 1 1]\n",
            "3 + 4 = 7\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.147568634017191\n",
            "Pred:[0 1 1 0 0 0 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "34 + 63 = 97\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.0272487304546868\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "18 + 60 = 78\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.02401101598000181\n",
            "Pred:[0 0 1 0 1 0 0 0]\n",
            "True:[0 0 1 0 1 0 0 0]\n",
            "39 + 1 = 40\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.03489539265412572\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "69 + 61 = 130\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.03627920947668831\n",
            "Pred:[1 0 0 0 0 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "114 + 17 = 131\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.024739391102767044\n",
            "Pred:[1 0 1 1 1 0 1 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "101 + 85 = 186\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.026887149426599064\n",
            "Pred:[1 0 1 0 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "121 + 53 = 174\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.03190083912149723\n",
            "Pred:[1 0 1 1 1 0 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "124 + 60 = 184\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.022665362557456787\n",
            "Pred:[0 1 0 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "0 + 95 = 95\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.018508036521846332\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "123 + 0 = 123\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.026624820651738407\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "20 + 118 = 138\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.025236670662475987\n",
            "Pred:[1 0 1 0 1 0 0 1]\n",
            "True:[1 0 1 0 1 0 0 1]\n",
            "52 + 117 = 169\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.021608871408160323\n",
            "Pred:[1 0 1 1 0 0 1 1]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "113 + 66 = 179\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.010820018101625382\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "109 + 81 = 190\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.03576321143026482\n",
            "Pred:[1 0 1 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "115 + 45 = 160\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.03943604308191221\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "107 + 30 = 137\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.018838007373181715\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "49 + 52 = 101\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.014423181040333846\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "72 + 28 = 100\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.015170078301665888\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "82 + 22 = 104\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.01110538842601686\n",
            "Pred:[0 1 0 1 0 1 0 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "36 + 48 = 84\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.021499034181107768\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "57 + 43 = 100\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.019116780863895778\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "62 + 42 = 104\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.019054680764194816\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "59 + 107 = 166\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.010656399767905198\n",
            "Pred:[1 0 1 1 1 0 1 1]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "105 + 82 = 187\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.012082193867468956\n",
            "Pred:[0 0 1 1 1 1 1 0]\n",
            "True:[0 0 1 1 1 1 1 0]\n",
            "27 + 35 = 62\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.012325182398469485\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "94 + 41 = 135\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.013667990429472513\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "94 + 39 = 133\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.004239973214508869\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "123 + 17 = 140\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.007141408862787743\n",
            "Pred:[1 0 1 1 0 0 1 1]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "80 + 99 = 179\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.004600437769470681\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "18 + 101 = 119\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.010384435280395331\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "104 + 24 = 128\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.012662604253041745\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "84 + 29 = 113\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.007125382003123622\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "34 + 84 = 118\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.007396592372828529\n",
            "Pred:[0 0 1 0 0 0 0 1]\n",
            "True:[0 0 1 0 0 0 0 1]\n",
            "29 + 4 = 33\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CSiQ9ug3JcwG",
        "outputId": "c5cb40d6-2126-43cb-d915-944b4cf616c6"
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# def d_tanh(x):\n",
        "\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 64\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.5\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# Xavier\n",
        "\n",
        "\n",
        "# He\n",
        "\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "\n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Loss:2.4231323008014085\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "83 + 41 = 0\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.2613246957524715\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "100 + 54 = 2\n",
            "------------\n",
            "iters:200\n",
            "Loss:0.8566240540787575\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "58 + 102 = 0\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.0174944285762684\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "34 + 74 = 190\n",
            "------------\n",
            "iters:400\n",
            "Loss:2.4038445161878244\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 0 0 0 1]\n",
            "38 + 123 = 255\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.5259236206880525\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 0 1 1 0]\n",
            "76 + 106 = 190\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.6708190624738155\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 1 1 0 1]\n",
            "28 + 33 = 127\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.5235275781396909\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "18 + 97 = 99\n",
            "------------\n",
            "iters:800\n",
            "Loss:1.0478968753649218\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 0 1 0 1 1 1 0]\n",
            "7 + 39 = 126\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.6809917696068717\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "59 + 71 = 0\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.4363676371087456\n",
            "Pred:[1 1 0 0 0 1 0 1]\n",
            "True:[1 1 1 0 0 1 0 1]\n",
            "110 + 119 = 197\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.2138394793152167\n",
            "Pred:[0 1 0 0 0 1 0 1]\n",
            "True:[0 0 1 1 1 1 0 1]\n",
            "8 + 53 = 69\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.2774015093314933\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "65 + 29 = 94\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.7392344053353679\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "21 + 76 = 119\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.24191264300989787\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "9 + 63 = 72\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.32176989152493884\n",
            "Pred:[1 1 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "103 + 48 = 215\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.01889924627919712\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "68 + 4 = 72\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.02338064897969178\n",
            "Pred:[0 1 0 0 1 1 0 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "65 + 11 = 76\n",
            "------------\n",
            "iters:1800\n",
            "Loss:2.27185331496434\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "73 + 54 = 133\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.1795340176882486\n",
            "Pred:[0 1 0 1 0 1 1 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "23 + 61 = 86\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.1286899323812807\n",
            "Pred:[1 0 1 1 1 0 1 1]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "112 + 75 = 187\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.03909715066206689\n",
            "Pred:[1 1 0 0 0 1 0 0]\n",
            "True:[1 1 0 0 0 1 0 0]\n",
            "72 + 124 = 196\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.00967814779417219\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "43 + 86 = 129\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.0037019859112743148\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "32 + 32 = 64\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.002226515533310337\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "56 + 0 = 56\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.2277973876729418\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "16 + 117 = 135\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.005514666665574295\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "119 + 19 = 138\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.004920506637139024\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "127 + 5 = 132\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.002307660313523116\n",
            "Pred:[0 1 0 0 1 0 1 1]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "39 + 36 = 75\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.007070082856553455\n",
            "Pred:[0 1 1 0 1 1 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "39 + 70 = 109\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.0014069327869736905\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "48 + 78 = 126\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.0003707873871411671\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "44 + 74 = 118\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.001031345812595911\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "13 + 120 = 133\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.00308386301516431\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "92 + 57 = 149\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.0007317707687826385\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "94 + 20 = 114\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.0002701498109175503\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "64 + 104 = 168\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.0011871077355716918\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "53 + 92 = 145\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.0006119712537206322\n",
            "Pred:[0 1 0 0 0 0 0 1]\n",
            "True:[0 1 0 0 0 0 0 1]\n",
            "53 + 12 = 65\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.001113528928134036\n",
            "Pred:[1 0 0 1 1 1 0 1]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "82 + 75 = 157\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.0009909855121485592\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "49 + 29 = 78\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.004462674341697427\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "0 + 107 = 107\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.0004642830675449266\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "101 + 28 = 129\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.0014317580920769294\n",
            "Pred:[1 0 1 0 0 0 1 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "50 + 113 = 163\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.00048482154334774193\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "72 + 77 = 149\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.0004325765371804679\n",
            "Pred:[0 0 1 1 0 0 1 0]\n",
            "True:[0 0 1 1 0 0 1 0]\n",
            "9 + 41 = 50\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.0004504578529354889\n",
            "Pred:[1 1 0 0 1 1 0 1]\n",
            "True:[1 1 0 0 1 1 0 1]\n",
            "111 + 94 = 205\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.0005463259995313188\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "52 + 81 = 133\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.0001550843158279154\n",
            "Pred:[0 0 0 1 0 1 0 1]\n",
            "True:[0 0 0 1 0 1 0 1]\n",
            "5 + 16 = 21\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.0005452352196679628\n",
            "Pred:[1 0 0 1 0 0 1 1]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "82 + 65 = 147\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.00015790289760865837\n",
            "Pred:[1 1 0 0 0 0 1 0]\n",
            "True:[1 1 0 0 0 0 1 0]\n",
            "90 + 104 = 194\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.000999828350829533\n",
            "Pred:[1 0 1 1 0 0 1 1]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "76 + 103 = 179\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.00025989746472231004\n",
            "Pred:[0 1 0 1 0 1 0 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "78 + 6 = 84\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.00012474969961867043\n",
            "Pred:[1 0 1 1 1 0 0 1]\n",
            "True:[1 0 1 1 1 0 0 1]\n",
            "65 + 120 = 185\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.00010866518955776307\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "17 + 106 = 123\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.00016975671034168713\n",
            "Pred:[1 0 1 1 0 1 1 1]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "113 + 70 = 183\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.00018646347174413182\n",
            "Pred:[1 0 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "86 + 70 = 156\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.0002639633270827916\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "114 + 1 = 115\n",
            "------------\n",
            "iters:5700\n",
            "Loss:1.914918422717502e-05\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "64 + 80 = 144\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.0001584151135856215\n",
            "Pred:[0 0 1 0 0 1 0 0]\n",
            "True:[0 0 1 0 0 1 0 0]\n",
            "6 + 30 = 36\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.00020592074178007072\n",
            "Pred:[0 1 0 1 1 0 0 1]\n",
            "True:[0 1 0 1 1 0 0 1]\n",
            "8 + 81 = 89\n",
            "------------\n",
            "iters:6000\n",
            "Loss:6.621692457543952e-05\n",
            "Pred:[0 1 0 0 1 1 0 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "59 + 17 = 76\n",
            "------------\n",
            "iters:6100\n",
            "Loss:8.423584154188506e-05\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "37 + 64 = 101\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.00013365773658250582\n",
            "Pred:[1 0 1 1 0 0 1 1]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "78 + 101 = 179\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.0001678589575993627\n",
            "Pred:[0 0 0 1 0 1 1 1]\n",
            "True:[0 0 0 1 0 1 1 1]\n",
            "14 + 9 = 23\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.0003431112453574675\n",
            "Pred:[1 0 0 1 1 1 0 1]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "30 + 127 = 157\n",
            "------------\n",
            "iters:6500\n",
            "Loss:1.2333038279748747e-05\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "42 + 84 = 126\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.00015163062120288453\n",
            "Pred:[0 0 1 0 0 1 1 1]\n",
            "True:[0 0 1 0 0 1 1 1]\n",
            "2 + 37 = 39\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.000136890366113752\n",
            "Pred:[1 0 1 1 0 1 1 1]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "57 + 126 = 183\n",
            "------------\n",
            "iters:6800\n",
            "Loss:3.208518221788097e-05\n",
            "Pred:[0 0 1 0 1 1 0 1]\n",
            "True:[0 0 1 0 1 1 0 1]\n",
            "3 + 42 = 45\n",
            "------------\n",
            "iters:6900\n",
            "Loss:9.872046637438918e-05\n",
            "Pred:[0 0 1 0 1 1 1 1]\n",
            "True:[0 0 1 0 1 1 1 1]\n",
            "39 + 8 = 47\n",
            "------------\n",
            "iters:7000\n",
            "Loss:9.080023268396587e-05\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "111 + 16 = 127\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.00022383878922130015\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "14 + 103 = 117\n",
            "------------\n",
            "iters:7200\n",
            "Loss:4.936380147727053e-05\n",
            "Pred:[1 0 0 1 0 0 1 1]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "51 + 96 = 147\n",
            "------------\n",
            "iters:7300\n",
            "Loss:9.131617260382855e-05\n",
            "Pred:[1 1 0 1 0 0 0 0]\n",
            "True:[1 1 0 1 0 0 0 0]\n",
            "91 + 117 = 208\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.00013482015446895722\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "61 + 58 = 119\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.00014191491560343003\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "116 + 57 = 173\n",
            "------------\n",
            "iters:7600\n",
            "Loss:6.301944144621286e-05\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "24 + 117 = 141\n",
            "------------\n",
            "iters:7700\n",
            "Loss:1.4834935536669318e-05\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "84 + 42 = 126\n",
            "------------\n",
            "iters:7800\n",
            "Loss:1.0758651649879966e-05\n",
            "Pred:[1 0 0 0 1 0 0 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "64 + 72 = 136\n",
            "------------\n",
            "iters:7900\n",
            "Loss:6.812122091846308e-05\n",
            "Pred:[1 0 0 1 0 1 1 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "89 + 61 = 150\n",
            "------------\n",
            "iters:8000\n",
            "Loss:6.149725859461677e-05\n",
            "Pred:[0 1 1 0 1 0 1 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "93 + 13 = 106\n",
            "------------\n",
            "iters:8100\n",
            "Loss:4.589760691745817e-05\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "83 + 49 = 132\n",
            "------------\n",
            "iters:8200\n",
            "Loss:9.629259851498983e-05\n",
            "Pred:[1 1 1 1 0 1 1 0]\n",
            "True:[1 1 1 1 0 1 1 0]\n",
            "120 + 126 = 246\n",
            "------------\n",
            "iters:8300\n",
            "Loss:2.7277129137653848e-05\n",
            "Pred:[0 1 0 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "81 + 14 = 95\n",
            "------------\n",
            "iters:8400\n",
            "Loss:3.355948861422392e-05\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "87 + 17 = 104\n",
            "------------\n",
            "iters:8500\n",
            "Loss:2.318172271550083e-05\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "50 + 74 = 124\n",
            "------------\n",
            "iters:8600\n",
            "Loss:3.0019256763983165e-05\n",
            "Pred:[0 0 0 1 1 1 0 1]\n",
            "True:[0 0 0 1 1 1 0 1]\n",
            "25 + 4 = 29\n",
            "------------\n",
            "iters:8700\n",
            "Loss:5.2473955456442294e-05\n",
            "Pred:[1 0 0 1 1 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "117 + 37 = 154\n",
            "------------\n",
            "iters:8800\n",
            "Loss:3.8892335850097685e-05\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "90 + 78 = 168\n",
            "------------\n",
            "iters:8900\n",
            "Loss:2.4940360420055995e-05\n",
            "Pred:[1 1 0 0 1 0 1 0]\n",
            "True:[1 1 0 0 1 0 1 0]\n",
            "86 + 116 = 202\n",
            "------------\n",
            "iters:9000\n",
            "Loss:2.4674519629445238e-05\n",
            "Pred:[1 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "25 + 118 = 143\n",
            "------------\n",
            "iters:9100\n",
            "Loss:2.075634616544623e-05\n",
            "Pred:[0 0 1 1 1 0 0 1]\n",
            "True:[0 0 1 1 1 0 0 1]\n",
            "3 + 54 = 57\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.00011263629408093178\n",
            "Pred:[1 0 1 1 0 1 0 0]\n",
            "True:[1 0 1 1 0 1 0 0]\n",
            "53 + 127 = 180\n",
            "------------\n",
            "iters:9300\n",
            "Loss:1.905102037176496e-05\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "32 + 78 = 110\n",
            "------------\n",
            "iters:9400\n",
            "Loss:2.4804528173121943e-05\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "35 + 17 = 52\n",
            "------------\n",
            "iters:9500\n",
            "Loss:6.255167377553635e-05\n",
            "Pred:[0 0 1 1 0 0 1 1]\n",
            "True:[0 0 1 1 0 0 1 1]\n",
            "22 + 29 = 51\n",
            "------------\n",
            "iters:9600\n",
            "Loss:2.2656209686423493e-05\n",
            "Pred:[0 1 1 0 0 0 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "89 + 8 = 97\n",
            "------------\n",
            "iters:9700\n",
            "Loss:9.875779272724928e-06\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "22 + 88 = 110\n",
            "------------\n",
            "iters:9800\n",
            "Loss:3.91869048494854e-05\n",
            "Pred:[1 0 1 0 0 0 0 1]\n",
            "True:[1 0 1 0 0 0 0 1]\n",
            "70 + 91 = 161\n",
            "------------\n",
            "iters:9900\n",
            "Loss:4.2234199901057885e-06\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "50 + 72 = 122\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl0iDAuVJMP_"
      },
      "source": [
        "## [try] 重みの初期化方法を変更してみよう\r\n",
        "Xavier, He\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "444BJFHlJgFt",
        "outputId": "d3c2e161-6bb1-4748-83bb-dac7ce5b6795"
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# def d_tanh(x):\n",
        "\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# Xavier\n",
        "W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "\n",
        "# He\n",
        "\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "\n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Loss:1.0324651317336313\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "38 + 78 = 0\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.0932923768779363\n",
            "Pred:[0 1 0 0 1 1 0 0]\n",
            "True:[1 0 1 1 0 0 1 0]\n",
            "76 + 102 = 76\n",
            "------------\n",
            "iters:200\n",
            "Loss:0.9995535281209313\n",
            "Pred:[0 1 0 0 0 0 1 1]\n",
            "True:[1 1 0 0 0 1 1 0]\n",
            "75 + 123 = 67\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.0048384520910634\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "105 + 60 = 0\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.0863354814306732\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "98 + 23 = 0\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.0037473819205909\n",
            "Pred:[1 0 1 1 1 1 1 1]\n",
            "True:[1 1 0 0 0 0 1 1]\n",
            "100 + 95 = 191\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.9764827457355405\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 1 0 1 1 0]\n",
            "55 + 127 = 255\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.9911195624186804\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 1 1 0 0 0]\n",
            "116 + 100 = 0\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.9670426521899007\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "101 + 45 = 0\n",
            "------------\n",
            "iters:900\n",
            "Loss:1.0279428742004386\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "37 + 94 = 255\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.0220937014491198\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "57 + 100 = 0\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.9798383567535353\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "86 + 49 = 0\n",
            "------------\n",
            "iters:1200\n",
            "Loss:1.0294185814726737\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "98 + 5 = 0\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.9816963715675873\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "127 + 56 = 119\n",
            "------------\n",
            "iters:1400\n",
            "Loss:1.00537231947725\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "12 + 97 = 223\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.8739633466873069\n",
            "Pred:[1 1 0 1 0 1 1 1]\n",
            "True:[1 1 0 1 0 0 1 1]\n",
            "105 + 106 = 215\n",
            "------------\n",
            "iters:1600\n",
            "Loss:1.0550135421972378\n",
            "Pred:[0 0 0 0 1 1 0 1]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "14 + 66 = 13\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.950273995580238\n",
            "Pred:[0 0 0 0 1 0 1 1]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "11 + 52 = 11\n",
            "------------\n",
            "iters:1800\n",
            "Loss:1.2486227427376322\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "103 + 19 = 0\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.8886543505042467\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "99 + 3 = 4\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.8716955884657053\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 1 0 0 1 0 0 1]\n",
            "105 + 96 = 129\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.905664301839216\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "96 + 4 = 64\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.9117878363783772\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 0 1 1 1 0 0 1]\n",
            "89 + 96 = 145\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.9214758867697322\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 1 0 1 1 0 0]\n",
            "113 + 123 = 255\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.7749424220184942\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 0 1 0 1 1 1 1]\n",
            "19 + 28 = 63\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.9130076529976097\n",
            "Pred:[1 0 0 1 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "91 + 75 = 150\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.7103627552598067\n",
            "Pred:[1 0 1 0 1 1 0 0]\n",
            "True:[1 0 1 0 1 1 0 0]\n",
            "92 + 80 = 172\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.9909478030354458\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "67 + 23 = 110\n",
            "------------\n",
            "iters:2800\n",
            "Loss:1.1710201495697574\n",
            "Pred:[0 0 0 1 1 1 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "90 + 7 = 29\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.9484305426524949\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "51 + 81 = 98\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.8360631218228995\n",
            "Pred:[1 1 0 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "12 + 109 = 219\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.7078824101285985\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "1 + 72 = 0\n",
            "------------\n",
            "iters:3200\n",
            "Loss:1.1673585437571248\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "106 + 28 = 116\n",
            "------------\n",
            "iters:3300\n",
            "Loss:1.151257689831491\n",
            "Pred:[1 1 1 0 1 1 1 0]\n",
            "True:[1 0 1 1 0 0 1 0]\n",
            "59 + 119 = 238\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.5514470133213479\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "34 + 29 = 63\n",
            "------------\n",
            "iters:3500\n",
            "Loss:1.0474463105649554\n",
            "Pred:[1 1 1 1 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "24 + 111 = 247\n",
            "------------\n",
            "iters:3600\n",
            "Loss:1.1983793280266903\n",
            "Pred:[0 1 1 1 1 1 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "50 + 79 = 125\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.7897834510485301\n",
            "Pred:[1 1 1 1 0 1 1 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "123 + 25 = 246\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.6556125944008192\n",
            "Pred:[1 1 1 1 0 1 0 1]\n",
            "True:[1 1 1 0 0 1 0 1]\n",
            "108 + 121 = 245\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.2836991686768557\n",
            "Pred:[1 1 0 1 0 1 1 0]\n",
            "True:[1 1 0 1 0 1 1 0]\n",
            "110 + 104 = 214\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.44174236370110964\n",
            "Pred:[0 1 0 1 1 1 0 1]\n",
            "True:[0 1 0 1 1 0 0 1]\n",
            "78 + 11 = 93\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.5663903270575947\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "110 + 2 = 124\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.5689298567472835\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[1 1 0 0 1 1 1 1]\n",
            "105 + 102 = 223\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.5495181929111846\n",
            "Pred:[1 0 1 1 0 1 0 1]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "96 + 83 = 181\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.2565127918119264\n",
            "Pred:[1 1 0 1 0 0 0 1]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "113 + 96 = 209\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.6863107205237431\n",
            "Pred:[0 1 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "101 + 36 = 73\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.09750926692993558\n",
            "Pred:[0 1 0 1 0 0 1 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "37 + 45 = 82\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.05376484754081169\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "65 + 37 = 102\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.310471074406751\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "50 + 49 = 99\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.1583408623324799\n",
            "Pred:[1 0 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "88 + 68 = 156\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.061102409068211634\n",
            "Pred:[0 0 0 1 1 0 1 0]\n",
            "True:[0 0 0 1 1 0 1 0]\n",
            "23 + 3 = 26\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.1820654290803958\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "111 + 41 = 152\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.07327083118559692\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "91 + 28 = 119\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.11734165783204682\n",
            "Pred:[1 1 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 0 0 0]\n",
            "109 + 83 = 192\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.07764355140755085\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[0 0 1 0 1 0 1 1]\n",
            "15 + 28 = 43\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.06731749672686713\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "28 + 93 = 121\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.08638363549793912\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "60 + 82 = 142\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.03575327281043653\n",
            "Pred:[1 0 1 0 0 0 1 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "98 + 65 = 163\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.03813364256724483\n",
            "Pred:[0 1 0 0 1 1 0 1]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "76 + 1 = 77\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.05729330151255308\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "17 + 86 = 103\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.04475329043278869\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "60 + 48 = 108\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.04286821158565504\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "86 + 16 = 102\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.07879487438117223\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "50 + 78 = 128\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.027349612110789456\n",
            "Pred:[0 1 1 0 0 0 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "85 + 12 = 97\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.03022425207806319\n",
            "Pred:[0 0 1 1 0 1 1 1]\n",
            "True:[0 0 1 1 0 1 1 1]\n",
            "25 + 30 = 55\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.01066940082230332\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "123 + 9 = 132\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.027191197907727706\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "45 + 114 = 159\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.01654188754162802\n",
            "Pred:[1 1 0 0 1 1 0 1]\n",
            "True:[1 1 0 0 1 1 0 1]\n",
            "117 + 88 = 205\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.01610819633053934\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "81 + 92 = 173\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.009249251808683218\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "89 + 13 = 102\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.018681915807128635\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "28 + 101 = 129\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.005095346004477221\n",
            "Pred:[1 0 1 0 0 1 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "79 + 85 = 164\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.011794438700964959\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "42 + 117 = 159\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.01816106851979342\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[0 0 1 0 1 0 1 1]\n",
            "37 + 6 = 43\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.0101522134910772\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "39 + 60 = 99\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.011561091745718517\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "42 + 87 = 129\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.017302015393147387\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "122 + 16 = 138\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.010125101143796974\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "31 + 80 = 111\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.006952156281933743\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "29 + 84 = 113\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.004869309863366108\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "56 + 45 = 101\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.010667272584948729\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "24 + 70 = 94\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.01096791823854329\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "60 + 72 = 132\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.01014550899698916\n",
            "Pred:[1 0 1 0 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "56 + 118 = 174\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.0051262767627155235\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "28 + 109 = 137\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.010113032332077854\n",
            "Pred:[0 0 1 0 0 1 0 0]\n",
            "True:[0 0 1 0 0 1 0 0]\n",
            "10 + 26 = 36\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.008347245668706618\n",
            "Pred:[1 1 1 0 0 0 1 0]\n",
            "True:[1 1 1 0 0 0 1 0]\n",
            "102 + 124 = 226\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.0018133358832740862\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "121 + 41 = 162\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.0027173579609905394\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "63 + 67 = 130\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.004450415132908299\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "15 + 84 = 99\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.001769716430992557\n",
            "Pred:[1 0 0 0 0 1 1 0]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "7 + 127 = 134\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.0013853498044475421\n",
            "Pred:[0 1 0 1 1 1 0 0]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "3 + 89 = 92\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.007631281093337781\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "14 + 126 = 140\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.00500669164517683\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "50 + 68 = 118\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.002978635770924369\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "53 + 60 = 113\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.0027193821658643338\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "88 + 45 = 133\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.0004673597450842561\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "87 + 7 = 94\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.003334110618453572\n",
            "Pred:[0 0 0 1 1 1 1 1]\n",
            "True:[0 0 0 1 1 1 1 1]\n",
            "11 + 20 = 31\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.0030907188037713985\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "23 + 84 = 107\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.002442737548948088\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "29 + 86 = 115\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.004607982821620956\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "110 + 52 = 162\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "62fOkGJtJgWg",
        "outputId": "f9d9ec40-545f-4f99-dd33-066890898dee"
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# def d_tanh(x):\n",
        "\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# Xavier\n",
        "\n",
        "\n",
        "# He\n",
        "W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "\n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Loss:0.9766977969763198\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "72 + 16 = 0\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.0253048322320604\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "104 + 82 = 0\n",
            "------------\n",
            "iters:200\n",
            "Loss:0.9770669204300746\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "64 + 106 = 254\n",
            "------------\n",
            "iters:300\n",
            "Loss:0.9676637818428953\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "114 + 37 = 255\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.006376172394762\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 0 0 1 0]\n",
            "17 + 33 = 255\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.0676105970316043\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "53 + 113 = 113\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.0418924658371054\n",
            "Pred:[1 1 1 1 0 0 1 1]\n",
            "True:[1 1 0 1 0 1 0 0]\n",
            "113 + 99 = 243\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.8865267712736125\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "46 + 34 = 68\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.9817685375295659\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 0 0 0 1 1]\n",
            "17 + 18 = 255\n",
            "------------\n",
            "iters:900\n",
            "Loss:1.0823725483859217\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "87 + 122 = 0\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.9305308750568435\n",
            "Pred:[1 1 1 0 0 1 0 0]\n",
            "True:[1 0 1 1 0 1 1 0]\n",
            "112 + 70 = 228\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.8992296820784083\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 0 1 1 1 0]\n",
            "41 + 5 = 127\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.7900441313021264\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "98 + 0 = 0\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.8642884545020786\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "70 + 116 = 254\n",
            "------------\n",
            "iters:1400\n",
            "Loss:1.0628945172289603\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "67 + 88 = 0\n",
            "------------\n",
            "iters:1500\n",
            "Loss:1.1057150129819469\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "124 + 63 = 66\n",
            "------------\n",
            "iters:1600\n",
            "Loss:1.1736906894048789\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "103 + 28 = 126\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.7317541923078713\n",
            "Pred:[0 1 0 1 0 1 1 1]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "41 + 46 = 87\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.9913855439904158\n",
            "Pred:[1 1 0 1 0 1 0 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "58 + 110 = 212\n",
            "------------\n",
            "iters:1900\n",
            "Loss:1.0778222366242174\n",
            "Pred:[1 1 0 1 0 1 1 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "61 + 107 = 214\n",
            "------------\n",
            "iters:2000\n",
            "Loss:1.0511685016773602\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "122 + 62 = 108\n",
            "------------\n",
            "iters:2100\n",
            "Loss:1.1675030993132933\n",
            "Pred:[1 1 1 1 0 1 1 1]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "119 + 33 = 247\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.9145406103924003\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "118 + 38 = 88\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.8848827006221706\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "38 + 62 = 88\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.834266754500095\n",
            "Pred:[1 1 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "34 + 118 = 220\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.7075719663970156\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "29 + 82 = 111\n",
            "------------\n",
            "iters:2600\n",
            "Loss:1.026222655087334\n",
            "Pred:[1 1 1 0 0 0 1 1]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "26 + 121 = 227\n",
            "------------\n",
            "iters:2700\n",
            "Loss:1.1609081781972055\n",
            "Pred:[1 1 0 1 0 0 0 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "63 + 111 = 208\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.609904149390666\n",
            "Pred:[1 1 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "97 + 61 = 222\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.5939673592247252\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "35 + 57 = 94\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.8290683556183687\n",
            "Pred:[1 1 0 0 1 1 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "48 + 123 = 207\n",
            "------------\n",
            "iters:3100\n",
            "Loss:1.0826360543511502\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 1 1 1 0 0 0 0]\n",
            "122 + 118 = 140\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.5468663874935005\n",
            "Pred:[0 1 0 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "58 + 37 = 95\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.9332678198229192\n",
            "Pred:[1 1 1 1 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "109 + 26 = 247\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.49860286506368323\n",
            "Pred:[1 1 0 1 1 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "49 + 105 = 218\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.689383619694165\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "107 + 20 = 127\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.7149166887263838\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "107 + 21 = 128\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.23281008950577753\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "76 + 40 = 116\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.5205310238944213\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "76 + 4 = 72\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.47190094112572106\n",
            "Pred:[0 1 0 1 1 0 0 1]\n",
            "True:[0 1 0 1 0 1 0 1]\n",
            "15 + 70 = 89\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.510013184840068\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "12 + 103 = 115\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.08435589281240885\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "40 + 16 = 56\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.5692804201402066\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "28 + 95 = 99\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.3097854515960137\n",
            "Pred:[1 1 0 1 1 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "40 + 114 = 218\n",
            "------------\n",
            "iters:4400\n",
            "Loss:1.0503422782542124\n",
            "Pred:[1 1 1 0 0 0 0 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "31 + 111 = 224\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.16461799228912316\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "88 + 12 = 100\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.35883552495839155\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "90 + 37 = 127\n",
            "------------\n",
            "iters:4700\n",
            "Loss:1.175961695482771\n",
            "Pred:[1 0 1 0 0 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "88 + 39 = 167\n",
            "------------\n",
            "iters:4800\n",
            "Loss:1.4133321471318774\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "55 + 73 = 254\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.05398260976203937\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "32 + 72 = 104\n",
            "------------\n",
            "iters:5000\n",
            "Loss:1.456638868746806\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "115 + 15 = 122\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.11161076240287242\n",
            "Pred:[0 1 0 0 0 1 0 1]\n",
            "True:[0 1 0 0 0 1 0 1]\n",
            "37 + 32 = 69\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.17329062008603158\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "36 + 109 = 145\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.2425207909671417\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 1 1 0 0]\n",
            "6 + 54 = 56\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.052034609463785395\n",
            "Pred:[0 1 0 1 0 1 1 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "42 + 44 = 86\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.4032176995248222\n",
            "Pred:[1 1 1 0 1 0 0 0]\n",
            "True:[1 1 1 0 1 0 1 0]\n",
            "119 + 115 = 232\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.07309204118101992\n",
            "Pred:[0 0 0 1 1 1 1 1]\n",
            "True:[0 0 0 1 1 1 1 1]\n",
            "30 + 1 = 31\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.15957541059758903\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "56 + 90 = 146\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.10100605401596513\n",
            "Pred:[0 0 0 1 1 0 0 0]\n",
            "True:[0 0 0 1 1 0 0 0]\n",
            "12 + 12 = 24\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.038625536989296765\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "34 + 98 = 132\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.17811643124623558\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "43 + 23 = 66\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.12333989851155541\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "90 + 54 = 144\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.04621127732183949\n",
            "Pred:[0 0 1 0 0 1 0 0]\n",
            "True:[0 0 1 0 0 1 0 0]\n",
            "11 + 25 = 36\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.140548884194365\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "102 + 30 = 132\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.04624708165475435\n",
            "Pred:[0 1 0 0 1 1 1 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "51 + 28 = 79\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.14453398296694459\n",
            "Pred:[1 1 0 0 0 1 1 0]\n",
            "True:[1 1 0 0 0 1 1 0]\n",
            "95 + 103 = 198\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.04019867500903095\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "97 + 27 = 124\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.03152512033140245\n",
            "Pred:[1 0 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "58 + 98 = 156\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.031514495344997846\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "89 + 25 = 114\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.04335221828048943\n",
            "Pred:[1 0 1 0 1 0 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "120 + 51 = 171\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.0549077301544092\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "24 + 125 = 149\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.028560265894830936\n",
            "Pred:[0 0 1 1 0 0 1 0]\n",
            "True:[0 0 1 1 0 0 1 0]\n",
            "6 + 44 = 50\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.10658971469831276\n",
            "Pred:[1 1 0 0 0 1 1 0]\n",
            "True:[1 1 0 0 0 1 1 0]\n",
            "79 + 119 = 198\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.03693846041905356\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "114 + 45 = 159\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.03256867155787611\n",
            "Pred:[1 1 0 1 1 1 0 1]\n",
            "True:[1 1 0 1 1 1 0 1]\n",
            "119 + 102 = 221\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.031739713317557997\n",
            "Pred:[1 1 0 0 0 0 1 0]\n",
            "True:[1 1 0 0 0 0 1 0]\n",
            "82 + 112 = 194\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.010392151858826153\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "99 + 1 = 100\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.015635524199659773\n",
            "Pred:[1 0 1 1 0 1 0 1]\n",
            "True:[1 0 1 1 0 1 0 1]\n",
            "99 + 82 = 181\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.012288205264895768\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "65 + 3 = 68\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.04061555630713973\n",
            "Pred:[1 0 0 0 0 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "37 + 94 = 131\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.021383019070633832\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "5 + 122 = 127\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.017668831498832097\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "89 + 24 = 113\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.021042664726381815\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "115 + 43 = 158\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.019145441639278574\n",
            "Pred:[1 0 1 0 1 0 0 1]\n",
            "True:[1 0 1 0 1 0 0 1]\n",
            "55 + 114 = 169\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.018724239554744084\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "91 + 75 = 166\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.011450698397526621\n",
            "Pred:[1 0 0 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "42 + 113 = 155\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.02685842324729058\n",
            "Pred:[1 1 0 1 1 0 0 0]\n",
            "True:[1 1 0 1 1 0 0 0]\n",
            "122 + 94 = 216\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.012535128616438403\n",
            "Pred:[1 1 0 0 0 1 1 0]\n",
            "True:[1 1 0 0 0 1 1 0]\n",
            "98 + 100 = 198\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.01022987721599503\n",
            "Pred:[1 0 0 0 1 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "34 + 105 = 139\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.027940050819699913\n",
            "Pred:[1 1 1 1 0 1 0 0]\n",
            "True:[1 1 1 1 0 1 0 0]\n",
            "118 + 126 = 244\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.01109907988650449\n",
            "Pred:[1 0 1 0 1 0 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "106 + 64 = 170\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.024343706594412512\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "53 + 63 = 116\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.010779328448820338\n",
            "Pred:[1 1 0 0 1 0 1 1]\n",
            "True:[1 1 0 0 1 0 1 1]\n",
            "115 + 88 = 203\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.01313355133847719\n",
            "Pred:[0 1 1 0 0 0 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "15 + 82 = 97\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.0030094532836965906\n",
            "Pred:[0 0 1 0 1 1 1 0]\n",
            "True:[0 0 1 0 1 1 1 0]\n",
            "45 + 1 = 46\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.010421232504989815\n",
            "Pred:[0 1 0 0 0 1 1 0]\n",
            "True:[0 1 0 0 0 1 1 0]\n",
            "55 + 15 = 70\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.007844102408599027\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "98 + 42 = 140\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.009238825885526023\n",
            "Pred:[1 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "86 + 57 = 143\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.0038364706002060457\n",
            "Pred:[0 1 0 0 1 0 1 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "61 + 13 = 74\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.0088294174328011\n",
            "Pred:[1 0 1 0 1 0 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "107 + 64 = 171\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTQWWT1YJOJd"
      },
      "source": [
        "## [try] 中間層の活性化関数を変更してみよう\r\n",
        "ReLU(勾配爆発を確認しよう)<br>\r\n",
        "tanh(numpyにtanhが用意されている。導関数をd_tanhとして作成しよう)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cUG2nxk_JhdW",
        "outputId": "9b97291d-82ce-46b0-d0d8-9890456e822a"
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        #z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "        z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        #delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "        #delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/DNN_code/common/functions.py:6: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1 + np.exp(-x))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Loss:0.9157630121476878\n",
            "Pred:[0 0 0 1 1 1 1 0]\n",
            "True:[0 0 1 1 1 1 0 0]\n",
            "6 + 54 = 30\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "111 + 37 = 0\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "44 + 108 = 0\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 0 1 1 1]\n",
            "22 + 33 = 0\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "82 + 38 = 0\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "123 + 33 = 0\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "118 + 7 = 0\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 1 1 0 0]\n",
            "54 + 6 = 0\n",
            "------------\n",
            "iters:800\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "100 + 63 = 0\n",
            "------------\n",
            "iters:900\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 0 1 0 1 0]\n",
            "10 + 32 = 0\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "30 + 26 = 0\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 1 0 1 1]\n",
            "48 + 11 = 0\n",
            "------------\n",
            "iters:1200\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 1 1 0 1]\n",
            "83 + 122 = 0\n",
            "------------\n",
            "iters:1300\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "40 + 81 = 0\n",
            "------------\n",
            "iters:1400\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 1 1 0 1 1 1]\n",
            "127 + 120 = 0\n",
            "------------\n",
            "iters:1500\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "75 + 28 = 0\n",
            "------------\n",
            "iters:1600\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "71 + 26 = 0\n",
            "------------\n",
            "iters:1700\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 0 0 1 1 1 1]\n",
            "10 + 5 = 0\n",
            "------------\n",
            "iters:1800\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "35 + 31 = 0\n",
            "------------\n",
            "iters:1900\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "97 + 54 = 0\n",
            "------------\n",
            "iters:2000\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "38 + 82 = 0\n",
            "------------\n",
            "iters:2100\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "50 + 22 = 0\n",
            "------------\n",
            "iters:2200\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "94 + 53 = 0\n",
            "------------\n",
            "iters:2300\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 1 1 0]\n",
            "106 + 92 = 0\n",
            "------------\n",
            "iters:2400\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 0 0 0]\n",
            "100 + 92 = 0\n",
            "------------\n",
            "iters:2500\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "32 + 51 = 0\n",
            "------------\n",
            "iters:2600\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "33 + 124 = 0\n",
            "------------\n",
            "iters:2700\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "89 + 54 = 0\n",
            "------------\n",
            "iters:2800\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 0 0 1]\n",
            "34 + 55 = 0\n",
            "------------\n",
            "iters:2900\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "29 + 62 = 0\n",
            "------------\n",
            "iters:3000\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "25 + 52 = 0\n",
            "------------\n",
            "iters:3100\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 0 1 0 1 1]\n",
            "6 + 37 = 0\n",
            "------------\n",
            "iters:3200\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "59 + 72 = 0\n",
            "------------\n",
            "iters:3300\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "54 + 37 = 0\n",
            "------------\n",
            "iters:3400\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "87 + 20 = 0\n",
            "------------\n",
            "iters:3500\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "35 + 55 = 0\n",
            "------------\n",
            "iters:3600\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "48 + 29 = 0\n",
            "------------\n",
            "iters:3700\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 1 0 0 0 0 0]\n",
            "102 + 122 = 0\n",
            "------------\n",
            "iters:3800\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 1 1 0]\n",
            "78 + 120 = 0\n",
            "------------\n",
            "iters:3900\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "93 + 55 = 0\n",
            "------------\n",
            "iters:4000\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "94 + 79 = 0\n",
            "------------\n",
            "iters:4100\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 0 0 1]\n",
            "66 + 127 = 0\n",
            "------------\n",
            "iters:4200\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "11 + 113 = 0\n",
            "------------\n",
            "iters:4300\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "102 + 0 = 0\n",
            "------------\n",
            "iters:4400\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 0 1 0 1]\n",
            "58 + 123 = 0\n",
            "------------\n",
            "iters:4500\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 0 1 1 0 1]\n",
            "15 + 30 = 0\n",
            "------------\n",
            "iters:4600\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 0 1 1 0]\n",
            "57 + 125 = 0\n",
            "------------\n",
            "iters:4700\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "27 + 91 = 0\n",
            "------------\n",
            "iters:4800\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "115 + 75 = 0\n",
            "------------\n",
            "iters:4900\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "58 + 46 = 0\n",
            "------------\n",
            "iters:5000\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 0 0 0 1]\n",
            "22 + 27 = 0\n",
            "------------\n",
            "iters:5100\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "96 + 69 = 0\n",
            "------------\n",
            "iters:5200\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 0 0 0 1]\n",
            "36 + 13 = 0\n",
            "------------\n",
            "iters:5300\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "87 + 79 = 0\n",
            "------------\n",
            "iters:5400\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "3 + 61 = 0\n",
            "------------\n",
            "iters:5500\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "64 + 83 = 0\n",
            "------------\n",
            "iters:5600\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "48 + 71 = 0\n",
            "------------\n",
            "iters:5700\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "51 + 32 = 0\n",
            "------------\n",
            "iters:5800\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "97 + 28 = 0\n",
            "------------\n",
            "iters:5900\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "125 + 17 = 0\n",
            "------------\n",
            "iters:6000\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "66 + 124 = 0\n",
            "------------\n",
            "iters:6100\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 0 1 1 0]\n",
            "39 + 15 = 0\n",
            "------------\n",
            "iters:6200\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "71 + 54 = 0\n",
            "------------\n",
            "iters:6300\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "93 + 23 = 0\n",
            "------------\n",
            "iters:6400\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 1 1 0 0 1]\n",
            "109 + 108 = 0\n",
            "------------\n",
            "iters:6500\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "64 + 23 = 0\n",
            "------------\n",
            "iters:6600\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "24 + 84 = 0\n",
            "------------\n",
            "iters:6700\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "23 + 67 = 0\n",
            "------------\n",
            "iters:6800\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 1 1 1 1 0]\n",
            "99 + 123 = 0\n",
            "------------\n",
            "iters:6900\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "53 + 120 = 0\n",
            "------------\n",
            "iters:7000\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "38 + 79 = 0\n",
            "------------\n",
            "iters:7100\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "66 + 5 = 0\n",
            "------------\n",
            "iters:7200\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "62 + 82 = 0\n",
            "------------\n",
            "iters:7300\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 1 0 1]\n",
            "94 + 103 = 0\n",
            "------------\n",
            "iters:7400\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "48 + 34 = 0\n",
            "------------\n",
            "iters:7500\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 1 0 1 0]\n",
            "126 + 76 = 0\n",
            "------------\n",
            "iters:7600\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "11 + 62 = 0\n",
            "------------\n",
            "iters:7700\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "27 + 73 = 0\n",
            "------------\n",
            "iters:7800\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 0 0 1]\n",
            "42 + 23 = 0\n",
            "------------\n",
            "iters:7900\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 1 1 0 1 1]\n",
            "113 + 106 = 0\n",
            "------------\n",
            "iters:8000\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "2 + 95 = 0\n",
            "------------\n",
            "iters:8100\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "97 + 62 = 0\n",
            "------------\n",
            "iters:8200\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 0 0 1 1 0]\n",
            "27 + 11 = 0\n",
            "------------\n",
            "iters:8300\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "81 + 71 = 0\n",
            "------------\n",
            "iters:8400\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "57 + 18 = 0\n",
            "------------\n",
            "iters:8500\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "55 + 20 = 0\n",
            "------------\n",
            "iters:8600\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 0 1 1]\n",
            "112 + 83 = 0\n",
            "------------\n",
            "iters:8700\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "106 + 0 = 0\n",
            "------------\n",
            "iters:8800\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 1 0 1]\n",
            "71 + 126 = 0\n",
            "------------\n",
            "iters:8900\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 1 0 1]\n",
            "88 + 109 = 0\n",
            "------------\n",
            "iters:9000\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "107 + 34 = 0\n",
            "------------\n",
            "iters:9100\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "81 + 77 = 0\n",
            "------------\n",
            "iters:9200\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "58 + 42 = 0\n",
            "------------\n",
            "iters:9300\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 0 0 1 1 1 0]\n",
            "13 + 1 = 0\n",
            "------------\n",
            "iters:9400\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 1 0 0 1]\n",
            "105 + 96 = 0\n",
            "------------\n",
            "iters:9500\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 1]\n",
            "29 + 52 = 0\n",
            "------------\n",
            "iters:9600\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 0 0 0 1 1]\n",
            "13 + 22 = 0\n",
            "------------\n",
            "iters:9700\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "75 + 5 = 0\n",
            "------------\n",
            "iters:9800\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "64 + 102 = 0\n",
            "------------\n",
            "iters:9900\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "3 + 93 = 0\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BZHAcVSDLtsm",
        "outputId": "47087d15-8b19-4d04-b36e-f564eb34a788"
      },
      "source": [
        "import numpy as np\r\n",
        "from common import functions\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "def d_tanh(x):\r\n",
        "    return 1/(np.cosh(x) ** 2)\r\n",
        "\r\n",
        "# データを用意\r\n",
        "# 2進数の桁数\r\n",
        "binary_dim = 8\r\n",
        "# 最大値 + 1\r\n",
        "largest_number = pow(2, binary_dim)\r\n",
        "# largest_numberまで2進数を用意\r\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\r\n",
        "\r\n",
        "input_layer_size = 2\r\n",
        "hidden_layer_size = 16\r\n",
        "output_layer_size = 1\r\n",
        "\r\n",
        "weight_init_std = 1\r\n",
        "learning_rate = 0.1\r\n",
        "\r\n",
        "iters_num = 10000\r\n",
        "plot_interval = 100\r\n",
        "\r\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\r\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\r\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\r\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# 勾配\r\n",
        "W_in_grad = np.zeros_like(W_in)\r\n",
        "W_out_grad = np.zeros_like(W_out)\r\n",
        "W_grad = np.zeros_like(W)\r\n",
        "\r\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\r\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\r\n",
        "y = np.zeros((output_layer_size, binary_dim))\r\n",
        "\r\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\r\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\r\n",
        "\r\n",
        "all_losses = []\r\n",
        "\r\n",
        "for i in range(iters_num):\r\n",
        "    \r\n",
        "    # A, B初期化 (a + b = d)\r\n",
        "    a_int = np.random.randint(largest_number/2)\r\n",
        "    a_bin = binary[a_int] # binary encoding\r\n",
        "    b_int = np.random.randint(largest_number/2)\r\n",
        "    b_bin = binary[b_int] # binary encoding\r\n",
        "    \r\n",
        "    # 正解データ\r\n",
        "    d_int = a_int + b_int\r\n",
        "    d_bin = binary[d_int]\r\n",
        "    \r\n",
        "    # 出力バイナリ\r\n",
        "    out_bin = np.zeros_like(d_bin)\r\n",
        "    \r\n",
        "    # 時系列全体の誤差\r\n",
        "    all_loss = 0    \r\n",
        "    \r\n",
        "    # 時系列ループ\r\n",
        "    for t in range(binary_dim):\r\n",
        "        # 入力値\r\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\r\n",
        "        # 時刻tにおける正解データ\r\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\r\n",
        "        \r\n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\r\n",
        "       # z[:,t+1] = functions.sigmoid(u[:,t+1])\r\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\r\n",
        "        z[:,t+1] = np.tanh(u[:,t+1])    \r\n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\r\n",
        "\r\n",
        "\r\n",
        "        #誤差\r\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\r\n",
        "        \r\n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \r\n",
        "        \r\n",
        "        all_loss += loss\r\n",
        "\r\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\r\n",
        "    \r\n",
        "    \r\n",
        "    for t in range(binary_dim)[::-1]:\r\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \r\n",
        "\r\n",
        "        #delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\r\n",
        "        #delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\r\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \r\n",
        "\r\n",
        "        # 勾配更新\r\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\r\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\r\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\r\n",
        "    \r\n",
        "    # 勾配適用\r\n",
        "    W_in -= learning_rate * W_in_grad\r\n",
        "    W_out -= learning_rate * W_out_grad\r\n",
        "    W -= learning_rate * W_grad\r\n",
        "    \r\n",
        "    W_in_grad *= 0\r\n",
        "    W_out_grad *= 0\r\n",
        "    W_grad *= 0\r\n",
        "    \r\n",
        "\r\n",
        "    if(i % plot_interval == 0):\r\n",
        "        all_losses.append(all_loss)        \r\n",
        "        print(\"iters:\" + str(i))\r\n",
        "        print(\"Loss:\" + str(all_loss))\r\n",
        "        print(\"Pred:\" + str(out_bin))\r\n",
        "        print(\"True:\" + str(d_bin))\r\n",
        "        out_int = 0\r\n",
        "        for index,x in enumerate(reversed(out_bin)):\r\n",
        "            out_int += x * pow(2, index)\r\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\r\n",
        "        print(\"------------\")\r\n",
        "\r\n",
        "lists = range(0, iters_num, plot_interval)\r\n",
        "plt.plot(lists, all_losses, label=\"loss\")\r\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Loss:2.1240955426252484\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "105 + 17 = 145\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.3393746703342784\n",
            "Pred:[1 0 1 0 1 1 1 0]\n",
            "True:[0 1 0 0 0 1 0 1]\n",
            "62 + 7 = 174\n",
            "------------\n",
            "iters:200\n",
            "Loss:0.7988403171821444\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "107 + 4 = 107\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.3576475195908266\n",
            "Pred:[0 1 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "37 + 119 = 85\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.376229207626363\n",
            "Pred:[0 1 0 1 1 1 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "92 + 72 = 92\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.9630768767932595\n",
            "Pred:[1 0 1 1 1 1 0 0]\n",
            "True:[0 0 1 0 1 0 0 0]\n",
            "23 + 17 = 188\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.2117969914943991\n",
            "Pred:[1 0 1 0 1 0 1 0]\n",
            "True:[0 0 1 0 0 1 0 0]\n",
            "3 + 33 = 170\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.0399204070030232\n",
            "Pred:[0 1 0 1 0 1 1 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "67 + 54 = 87\n",
            "------------\n",
            "iters:800\n",
            "Loss:1.1339297522354794\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 1 0 1 0 0 1]\n",
            "97 + 72 = 149\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.8904735272546465\n",
            "Pred:[1 0 1 1 0 1 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "72 + 67 = 183\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.0386853862168848\n",
            "Pred:[0 0 1 0 0 0 1 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "57 + 31 = 34\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.1174786227798323\n",
            "Pred:[1 1 0 1 0 1 1 1]\n",
            "True:[0 0 1 1 1 0 0 1]\n",
            "14 + 43 = 215\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.998687117378261\n",
            "Pred:[1 0 1 1 1 0 1 0]\n",
            "True:[0 0 1 0 0 0 0 0]\n",
            "11 + 21 = 186\n",
            "------------\n",
            "iters:1300\n",
            "Loss:1.106761562404956\n",
            "Pred:[0 1 0 1 1 0 1 0]\n",
            "True:[1 1 1 0 1 0 1 0]\n",
            "114 + 120 = 90\n",
            "------------\n",
            "iters:1400\n",
            "Loss:1.1357056243019688\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "83 + 60 = 127\n",
            "------------\n",
            "iters:1500\n",
            "Loss:1.254782688227694\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "42 + 81 = 137\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.8189294433271401\n",
            "Pred:[1 1 0 0 1 1 0 0]\n",
            "True:[1 1 0 1 1 1 0 0]\n",
            "94 + 126 = 204\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.9630651994736114\n",
            "Pred:[0 1 0 1 1 1 0 0]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "29 + 35 = 92\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.9686263125476984\n",
            "Pred:[1 0 1 1 0 1 1 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "77 + 9 = 182\n",
            "------------\n",
            "iters:1900\n",
            "Loss:1.1217499768661314\n",
            "Pred:[0 0 1 0 0 0 1 0]\n",
            "True:[1 1 0 1 0 0 1 0]\n",
            "85 + 125 = 34\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.9776782443356068\n",
            "Pred:[1 1 0 1 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "58 + 116 = 222\n",
            "------------\n",
            "iters:2100\n",
            "Loss:1.0606913179751778\n",
            "Pred:[0 1 0 1 0 1 0 1]\n",
            "True:[0 0 1 1 0 0 0 1]\n",
            "28 + 21 = 85\n",
            "------------\n",
            "iters:2200\n",
            "Loss:1.0710942904452843\n",
            "Pred:[1 1 0 0 1 0 1 1]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "108 + 75 = 203\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.8208099250767604\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "87 + 9 = 102\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.7784155303014259\n",
            "Pred:[1 1 1 0 0 1 1 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "64 + 43 = 231\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.6382236671548407\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "123 + 63 = 138\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.6197841338416298\n",
            "Pred:[1 0 1 1 1 0 1 1]\n",
            "True:[1 1 0 1 1 0 1 1]\n",
            "124 + 95 = 187\n",
            "------------\n",
            "iters:2700\n",
            "Loss:1.118074066498637\n",
            "Pred:[1 1 1 0 1 1 1 1]\n",
            "True:[1 0 1 1 0 0 0 1]\n",
            "123 + 54 = 239\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.9423116485939455\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 1 1 1 1 0 0]\n",
            "64 + 124 = 148\n",
            "------------\n",
            "iters:2900\n",
            "Loss:1.1720896417979578\n",
            "Pred:[1 1 0 1 0 0 0 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "2 + 125 = 209\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.6629581008451482\n",
            "Pred:[1 0 0 1 1 0 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "109 + 61 = 154\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.7291515442274393\n",
            "Pred:[1 0 0 1 0 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "22 + 109 = 147\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.6870058166546382\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "73 + 5 = 142\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.6209131488201933\n",
            "Pred:[1 0 1 1 0 1 1 1]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "117 + 66 = 183\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.6051997369073522\n",
            "Pred:[1 0 1 0 0 1 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "111 + 60 = 167\n",
            "------------\n",
            "iters:3500\n",
            "Loss:1.0868424719697818\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "34 + 58 = 100\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.4367303413991588\n",
            "Pred:[0 0 1 0 1 0 0 1]\n",
            "True:[0 0 1 1 1 0 0 1]\n",
            "32 + 25 = 41\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.9677219079636519\n",
            "Pred:[0 0 0 0 1 0 0 0]\n",
            "True:[1 1 1 0 1 1 0 0]\n",
            "122 + 114 = 8\n",
            "------------\n",
            "iters:3800\n",
            "Loss:1.1820997500013182\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "113 + 23 = 100\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.8611977229009334\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "46 + 101 = 137\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.9867424674149682\n",
            "Pred:[0 1 0 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "46 + 67 = 87\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.7665805456892578\n",
            "Pred:[1 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "7 + 102 = 245\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.7998120281340525\n",
            "Pred:[1 0 0 1 1 1 0 0]\n",
            "True:[1 1 0 1 1 0 1 0]\n",
            "125 + 93 = 156\n",
            "------------\n",
            "iters:4300\n",
            "Loss:1.5284140533337862\n",
            "Pred:[0 0 1 1 1 0 1 1]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "120 + 89 = 59\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.8020576436888994\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 1 0 0 0 0 0]\n",
            "116 + 108 = 0\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.6384882147550873\n",
            "Pred:[1 1 1 0 1 0 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "111 + 60 = 235\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.7738576090829017\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "127 + 39 = 0\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.8926210526077814\n",
            "Pred:[1 1 1 0 1 1 1 0]\n",
            "True:[1 1 0 1 0 0 1 0]\n",
            "116 + 94 = 238\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.5011671115317978\n",
            "Pred:[0 0 0 1 1 1 0 1]\n",
            "True:[0 0 1 1 1 1 0 1]\n",
            "38 + 23 = 29\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.7262665242591038\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 0 1 1 0 0 0 1]\n",
            "23 + 26 = 1\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.8670936932777158\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 1 1 0]\n",
            "111 + 87 = 128\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.7531581118756894\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "21 + 124 = 129\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.7895962116128137\n",
            "Pred:[1 0 1 0 0 0 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "127 + 13 = 160\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.7616510637201399\n",
            "Pred:[0 0 0 1 1 0 1 1]\n",
            "True:[1 1 0 0 1 1 1 1]\n",
            "89 + 118 = 27\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.7479088697317988\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 1 0 0 1 1 1 0]\n",
            "86 + 120 = 254\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.840098653673079\n",
            "Pred:[1 1 0 1 1 1 0 1]\n",
            "True:[1 0 1 1 0 0 0 1]\n",
            "59 + 118 = 221\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.9131320196310848\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "52 + 32 = 100\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.6954224792920007\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 1 1 0 0 1 1 0]\n",
            "110 + 120 = 254\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.9855392214455383\n",
            "Pred:[0 0 1 0 0 0 0 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "43 + 82 = 33\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.7100405870307686\n",
            "Pred:[0 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "82 + 66 = 16\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.7661214235289544\n",
            "Pred:[1 0 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "7 + 116 = 191\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.590318641365732\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "126 + 11 = 129\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.7315088518241987\n",
            "Pred:[0 0 1 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "80 + 80 = 32\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.5901722437746435\n",
            "Pred:[0 0 0 0 1 1 0 1]\n",
            "True:[0 0 0 1 1 0 0 1]\n",
            "1 + 24 = 13\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.7222717841586984\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "112 + 97 = 1\n",
            "------------\n",
            "iters:6500\n",
            "Loss:1.1951245805638548\n",
            "Pred:[0 1 0 1 0 0 0 1]\n",
            "True:[0 0 1 0 1 1 1 1]\n",
            "25 + 22 = 81\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.708956963931916\n",
            "Pred:[1 0 1 0 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "46 + 109 = 171\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.9184870566734163\n",
            "Pred:[1 1 0 1 0 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "58 + 109 = 215\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.9200720268102471\n",
            "Pred:[1 0 1 0 0 1 0 1]\n",
            "True:[1 1 0 1 1 1 1 1]\n",
            "109 + 114 = 165\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.46293131245362995\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "73 + 45 = 126\n",
            "------------\n",
            "iters:7000\n",
            "Loss:1.0382675669732393\n",
            "Pred:[1 0 1 0 1 1 0 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "75 + 47 = 172\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.5186484938030479\n",
            "Pred:[0 1 0 1 0 0 0 1]\n",
            "True:[0 1 0 0 0 0 0 1]\n",
            "56 + 9 = 81\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.7761959230157698\n",
            "Pred:[0 0 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "21 + 77 = 40\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.3614451021888693\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "31 + 77 = 124\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.8556926351369141\n",
            "Pred:[0 1 0 0 0 1 1 0]\n",
            "True:[0 0 1 1 0 1 1 0]\n",
            "28 + 26 = 70\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.7922543651887185\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "112 + 63 = 137\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.6684162826301819\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "119 + 54 = 141\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.78492169102784\n",
            "Pred:[1 1 0 1 1 0 1 1]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "92 + 117 = 219\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.7608655723330939\n",
            "Pred:[0 0 0 1 1 0 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "0 + 88 = 24\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.9674372387868335\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[0 0 1 1 1 1 0 1]\n",
            "12 + 49 = 43\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.34320683483759834\n",
            "Pred:[1 1 0 0 1 0 1 1]\n",
            "True:[1 1 0 0 1 0 1 1]\n",
            "91 + 112 = 203\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.5813881653220999\n",
            "Pred:[0 1 0 0 0 1 0 1]\n",
            "True:[0 0 1 0 0 1 0 1]\n",
            "3 + 34 = 69\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.5678530714214537\n",
            "Pred:[0 1 0 0 0 0 1 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "56 + 41 = 67\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.6932263124817234\n",
            "Pred:[0 0 0 1 0 1 1 1]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "82 + 101 = 23\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.2611601203358268\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "97 + 35 = 132\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.9849151384383856\n",
            "Pred:[1 1 1 1 1 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "126 + 4 = 250\n",
            "------------\n",
            "iters:8600\n",
            "Loss:1.1254767390402\n",
            "Pred:[0 0 1 0 0 1 1 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "24 + 58 = 38\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.8131261936353996\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 0 1 0 1 1 0 1]\n",
            "33 + 12 = 113\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.5176995895247386\n",
            "Pred:[1 1 1 1 0 1 1 1]\n",
            "True:[1 0 1 1 0 1 0 1]\n",
            "84 + 97 = 247\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.5705760870742387\n",
            "Pred:[1 1 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "50 + 81 = 199\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.8448129673154967\n",
            "Pred:[1 1 0 1 0 0 0 1]\n",
            "True:[1 1 1 0 1 0 0 1]\n",
            "107 + 126 = 209\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.6149552406774088\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "118 + 37 = 151\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.45722091660349734\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "97 + 33 = 2\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.6680868050564024\n",
            "Pred:[1 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "18 + 81 = 235\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.7043033822860316\n",
            "Pred:[1 1 0 0 0 1 1 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "62 + 41 = 199\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.7433653466760952\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 1 0 1 0 1 1 0]\n",
            "103 + 111 = 144\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.6910725386355243\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "60 + 33 = 223\n",
            "------------\n",
            "iters:9700\n",
            "Loss:1.4232620654318873\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "36 + 92 = 88\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.7865932069979379\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "51 + 119 = 138\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.3312736393849168\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "70 + 78 = 148\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
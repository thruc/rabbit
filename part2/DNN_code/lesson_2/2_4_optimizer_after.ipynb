{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"colab":{"name":"2_4_optimizer_after.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"8cNl2QA_Rnv5","colab_type":"text"},"source":["# 準備"]},{"cell_type":"markdown","metadata":{"id":"YkwjN1jNVAYy","colab_type":"text"},"source":["## Googleドライブのマウント"]},{"cell_type":"code","metadata":{"id":"pvFXpiH3EVC1","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Ub7RYdeY6pK","colab_type":"text"},"source":["## sys.pathの設定"]},{"cell_type":"markdown","metadata":{"id":"oql7L19rEsWi","colab_type":"text"},"source":["以下では，Googleドライブのマイドライブ直下にDNN_codeフォルダを置くことを仮定しています．必要に応じて，パスを変更してください．"]},{"cell_type":"code","metadata":{"id":"7Ic2JzkvFX59","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/DNN_code')\n","sys.path.append('/content/drive/My Drive/DNN_code/lesson_2')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WjOHsaKWm6_G","colab_type":"text"},"source":["# optimizer"]},{"cell_type":"markdown","metadata":{"id":"JtUYfk8Pm6_H","colab_type":"text"},"source":["## SGD"]},{"cell_type":"code","metadata":{"id":"Hd7yE-pAm6_I","colab_type":"code","colab":{}},"source":["import numpy as np\n","from collections import OrderedDict\n","from common import layers\n","from data.mnist import load_mnist\n","import matplotlib.pyplot as plt\n","from multi_layer_net import MultiLayerNet\n","\n","\n","# データの読み込み\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n","\n","print(\"データ読み込み完了\")\n","\n","# batch_normalizationの設定 =======================\n","# use_batchnorm = True\n","use_batchnorm = False\n","# ====================================================\n","\n","\n","network = MultiLayerNet(input_size=784, hidden_size_list=[40, 20], output_size=10, activation='sigmoid', weight_init_std=0.01,\n","                       use_batchnorm=use_batchnorm)\n","\n","iters_num = 1000\n","train_size = x_train.shape[0]\n","batch_size = 100\n","learning_rate = 0.01\n","\n","train_loss_list = []\n","accuracies_train = []\n","accuracies_test = []\n","\n","plot_interval=10\n","\n","for i in range(iters_num):\n","    batch_mask = np.random.choice(train_size, batch_size)\n","    x_batch = x_train[batch_mask]\n","    d_batch = d_train[batch_mask]\n","\n","    # 勾配\n","    grad = network.gradient(x_batch, d_batch)\n","    \n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\n","        network.params[key] -= learning_rate * grad[key]\n","        \n","        loss = network.loss(x_batch, d_batch)\n","        train_loss_list.append(loss)\n","    \n","    \n","    if (i + 1) % plot_interval == 0:\n","        accr_test = network.accuracy(x_test, d_test)\n","        accuracies_test.append(accr_test)        \n","        accr_train = network.accuracy(x_batch, d_batch)\n","        accuracies_train.append(accr_train)\n","        \n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\n","\n","        \n","lists = range(0, iters_num, plot_interval)\n","plt.plot(lists, accuracies_train, label=\"training set\")\n","plt.plot(lists, accuracies_test,  label=\"test set\")\n","plt.legend(loc=\"lower right\")\n","plt.title(\"accuracy\")\n","plt.xlabel(\"count\")\n","plt.ylabel(\"accuracy\")\n","plt.ylim(0, 1.0)\n","# グラフの表示\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bHV0_883m6_N","colab_type":"text"},"source":["## Momentum"]},{"cell_type":"code","metadata":{"id":"wbLKrAzkm6_O","colab_type":"code","colab":{}},"source":["\n","# データの読み込み\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n","\n","print(\"データ読み込み完了\")\n","\n","# batch_normalizationの設定 =======================\n","# use_batchnorm = True\n","use_batchnorm = False\n","# ====================================================\n","\n","network = MultiLayerNet(input_size=784, hidden_size_list=[40, 20], output_size=10, activation='sigmoid', weight_init_std=0.01,\n","                       use_batchnorm=use_batchnorm)\n","\n","iters_num = 1000\n","train_size = x_train.shape[0]\n","batch_size = 100\n","learning_rate = 0.3\n","# 慣性\n","momentum = 0.9\n","\n","train_loss_list = []\n","accuracies_train = []\n","accuracies_test = []\n","\n","plot_interval=10\n","\n","for i in range(iters_num):\n","    batch_mask = np.random.choice(train_size, batch_size)\n","    x_batch = x_train[batch_mask]\n","    d_batch = d_train[batch_mask]\n","\n","    # 勾配\n","    grad = network.gradient(x_batch, d_batch)\n","    if i == 0:\n","        v = {}\n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\n","        if i == 0:\n","            v[key] = np.zeros_like(network.params[key])\n","        v[key] = momentum * v[key] - learning_rate * grad[key]\n","        network.params[key] += v[key]\n","\n","        loss = network.loss(x_batch, d_batch)\n","        train_loss_list.append(loss)\n","        \n","    if (i + 1) % plot_interval == 0:\n","        accr_test = network.accuracy(x_test, d_test)\n","        accuracies_test.append(accr_test)        \n","        accr_train = network.accuracy(x_batch, d_batch)\n","        accuracies_train.append(accr_train)\n","\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\n","        \n","        \n","lists = range(0, iters_num, plot_interval)\n","plt.plot(lists, accuracies_train, label=\"training set\")\n","plt.plot(lists, accuracies_test,  label=\"test set\")\n","plt.legend(loc=\"lower right\")\n","plt.title(\"accuracy\")\n","plt.xlabel(\"count\")\n","plt.ylabel(\"accuracy\")\n","plt.ylim(0, 1.0)\n","# グラフの表示\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MgULIQT9m6_R","colab_type":"text"},"source":["## AdaGrad"]},{"cell_type":"code","metadata":{"id":"ZtyEO3czm6_R","colab_type":"code","colab":{}},"source":["\n","# データの読み込み\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n","\n","print(\"データ読み込み完了\")\n","\n","# batch_normalizationの設定 =======================\n","# use_batchnorm = True\n","use_batchnorm = False\n","# ====================================================\n","\n","network = MultiLayerNet(input_size=784, hidden_size_list=[40, 20], output_size=10, activation='sigmoid', weight_init_std=0.01,\n","                       use_batchnorm=use_batchnorm)\n","\n","iters_num = 1000\n","train_size = x_train.shape[0]\n","batch_size = 100\n","learning_rate = 0.1\n","\n","train_loss_list = []\n","accuracies_train = []\n","accuracies_test = []\n","\n","plot_interval=10\n","\n","for i in range(iters_num):\n","    batch_mask = np.random.choice(train_size, batch_size)\n","    x_batch = x_train[batch_mask]\n","    d_batch = d_train[batch_mask]\n","\n","    # 勾配\n","    grad = network.gradient(x_batch, d_batch)\n","    if i == 0:\n","        h = {}\n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\n","        if i == 0:\n","            h[key] = np.full_like(network.params[key], 1e-4)\n","        else:\n","            h[key] += np.square(grad[key])\n","        network.params[key] -= learning_rate * grad[key] / (np.sqrt(h[key]))\n","\n","        loss = network.loss(x_batch, d_batch)\n","        train_loss_list.append(loss)        \n","        \n","        \n","    if (i + 1) % plot_interval == 0:\n","        accr_test = network.accuracy(x_test, d_test)\n","        accuracies_test.append(accr_test)        \n","        accr_train = network.accuracy(x_batch, d_batch)\n","        accuracies_train.append(accr_train)\n","        \n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\n","        \n","        \n","lists = range(0, iters_num, plot_interval)\n","plt.plot(lists, accuracies_train, label=\"training set\")\n","plt.plot(lists, accuracies_test,  label=\"test set\")\n","plt.legend(loc=\"lower right\")\n","plt.title(\"accuracy\")\n","plt.xlabel(\"count\")\n","plt.ylabel(\"accuracy\")\n","plt.ylim(0, 1.0)\n","# グラフの表示\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jX7arYPim6_U","colab_type":"text"},"source":["## RMSprop"]},{"cell_type":"code","metadata":{"id":"hNjyEZlHm6_V","colab_type":"code","colab":{}},"source":["\n","# データの読み込み\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n","\n","print(\"データ読み込み完了\")\n","\n","# batch_normalizationの設定 =======================\n","# use_batchnorm = True\n","use_batchnorm = False\n","# ====================================================\n","\n","network = MultiLayerNet(input_size=784, hidden_size_list=[40, 20], output_size=10, activation='sigmoid', weight_init_std=0.01,\n","                       use_batchnorm=use_batchnorm)\n","\n","iters_num = 1000\n","train_size = x_train.shape[0]\n","batch_size = 100\n","learning_rate = 0.01\n","decay_rate = 0.99\n","\n","train_loss_list = []\n","accuracies_train = []\n","accuracies_test = []\n","\n","plot_interval=10\n","\n","for i in range(iters_num):\n","    batch_mask = np.random.choice(train_size, batch_size)\n","    x_batch = x_train[batch_mask]\n","    d_batch = d_train[batch_mask]\n","\n","    # 勾配\n","    grad = network.gradient(x_batch, d_batch)\n","    if i == 0:\n","        h = {}\n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\n","        if i == 0:\n","            h[key] = np.zeros_like(network.params[key])\n","        h[key] *= decay_rate\n","        h[key] += (1 - decay_rate) * np.square(grad[key])\n","        network.params[key] -= learning_rate * grad[key] / (np.sqrt(h[key]) + 1e-7)\n","\n","        loss = network.loss(x_batch, d_batch)\n","        train_loss_list.append(loss)                \n","        \n","    if (i + 1) % plot_interval == 0:\n","        accr_test = network.accuracy(x_test, d_test)\n","        accuracies_test.append(accr_test)        \n","        accr_train = network.accuracy(x_batch, d_batch)\n","        accuracies_train.append(accr_train)\n","        \n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\n","        \n","        \n","lists = range(0, iters_num, plot_interval)\n","plt.plot(lists, accuracies_train, label=\"training set\")\n","plt.plot(lists, accuracies_test,  label=\"test set\")\n","plt.legend(loc=\"lower right\")\n","plt.title(\"accuracy\")\n","plt.xlabel(\"count\")\n","plt.ylabel(\"accuracy\")\n","plt.ylim(0, 1.0)\n","# グラフの表示\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wf0BHsbpm6_X","colab_type":"text"},"source":["## Adam"]},{"cell_type":"code","metadata":{"id":"bBN0j5pUm6_Y","colab_type":"code","colab":{}},"source":["\n","# データの読み込み\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n","\n","print(\"データ読み込み完了\")\n","\n","# batch_normalizationの設定 =======================\n","# use_batchnorm = True\n","use_batchnorm = False\n","# ====================================================\n","\n","network = MultiLayerNet(input_size=784, hidden_size_list=[40, 20], output_size=10, activation='sigmoid', weight_init_std=0.01,\n","                       use_batchnorm=use_batchnorm)\n","\n","iters_num = 1000\n","train_size = x_train.shape[0]\n","batch_size = 100\n","learning_rate = 0.01\n","beta1 = 0.9\n","beta2 = 0.999\n","\n","train_loss_list = []\n","accuracies_train = []\n","accuracies_test = []\n","\n","plot_interval=10\n","\n","for i in range(iters_num):\n","    batch_mask = np.random.choice(train_size, batch_size)\n","    x_batch = x_train[batch_mask]\n","    d_batch = d_train[batch_mask]\n","\n","    # 勾配\n","    grad = network.gradient(x_batch, d_batch)\n","    if i == 0:\n","        m = {}\n","        v = {}\n","    learning_rate_t  = learning_rate * np.sqrt(1.0 - beta2 ** (i + 1)) / (1.0 - beta1 ** (i + 1))    \n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\n","        if i == 0:\n","            m[key] = np.zeros_like(network.params[key])\n","            v[key] = np.zeros_like(network.params[key])\n","            \n","        m[key] += (1 - beta1) * (grad[key] - m[key])\n","        v[key] += (1 - beta2) * (grad[key] ** 2 - v[key])            \n","        network.params[key] -= learning_rate_t * m[key] / (np.sqrt(v[key]) + 1e-7)                \n","        \n","        loss = network.loss(x_batch, d_batch)\n","        train_loss_list.append(loss)        \n","        \n","    if (i + 1) % plot_interval == 0:\n","        accr_test = network.accuracy(x_test, d_test)\n","        accuracies_test.append(accr_test)        \n","        accr_train = network.accuracy(x_batch, d_batch)\n","        accuracies_train.append(accr_train)\n","        \n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\n","                \n","\n","lists = range(0, iters_num, plot_interval)\n","plt.plot(lists, accuracies_train, label=\"training set\")\n","plt.plot(lists, accuracies_test,  label=\"test set\")\n","plt.legend(loc=\"lower right\")\n","plt.title(\"accuracy\")\n","plt.xlabel(\"count\")\n","plt.ylabel(\"accuracy\")\n","plt.ylim(0, 1.0)\n","# グラフの表示\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9c2vsV0Em6_a","colab_type":"text"},"source":["---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","## [try] 活性化関数と重みの初期化方法を変更して違いを見てみよう\n","初期状態ではsigmoid - gauss<br>\n","activationはReLU、weight_init_stdは別の数値や'Xavier'・'He'に変更可能"]},{"cell_type":"markdown","metadata":{"id":"9lwlInXvm6_b","colab_type":"text"},"source":["## [try] バッチ正規化をして変化を見てみよう\n","use_batchnormをTrueにしよう\n","\n","---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"]}]}
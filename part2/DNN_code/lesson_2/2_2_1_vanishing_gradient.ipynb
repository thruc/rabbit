{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"colab":{"name":"2_2_1_vanishing_gradient.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"8cNl2QA_Rnv5","colab_type":"text"},"source":["# 準備"]},{"cell_type":"markdown","metadata":{"id":"YkwjN1jNVAYy","colab_type":"text"},"source":["## Googleドライブのマウント"]},{"cell_type":"code","metadata":{"id":"pvFXpiH3EVC1","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Ub7RYdeY6pK","colab_type":"text"},"source":["## sys.pathの設定"]},{"cell_type":"markdown","metadata":{"id":"oql7L19rEsWi","colab_type":"text"},"source":["以下では，Googleドライブのマイドライブ直下にDNN_codeフォルダを置くことを仮定しています．必要に応じて，パスを変更してください．"]},{"cell_type":"code","metadata":{"id":"7Ic2JzkvFX59","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/DNN_code')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aEP7EDibgeIY","colab_type":"text"},"source":["# vanishing gradient"]},{"cell_type":"markdown","metadata":{"id":"AGgP5iAHgeIZ","colab_type":"text"},"source":["## sigmoid - gauss"]},{"cell_type":"code","metadata":{"id":"Xew8ajdYgeIa","colab_type":"code","colab":{}},"source":["import numpy as np\n","from common import layers\n","from collections import OrderedDict\n","from common import functions\n","from data.mnist import load_mnist\n","import matplotlib.pyplot as plt\n","\n","# mnistをロード\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n","train_size = len(x_train)\n","\n","print(\"データ読み込み完了\")\n","\n","# 重み初期値補正係数\n","wieght_init = 0.01\n","#入力層サイズ\n","input_layer_size = 784\n","#中間層サイズ\n","hidden_layer_1_size = 40\n","hidden_layer_2_size = 20\n","\n","#出力層サイズ\n","output_layer_size = 10\n","# 繰り返し数\n","iters_num = 2000\n","# ミニバッチサイズ\n","batch_size = 100\n","# 学習率\n","learning_rate = 0.1\n","# 描写頻度\n","plot_interval=10\n","\n","# 初期設定\n","def init_network():\n","    network = {} \n","    network['W1'] = wieght_init * np.random.randn(input_layer_size, hidden_layer_1_size)\n","    network['W2'] = wieght_init * np.random.randn(hidden_layer_1_size, hidden_layer_2_size)\n","    network['W3'] = wieght_init * np.random.randn(hidden_layer_2_size, output_layer_size)\n","\n","    network['b1'] = np.zeros(hidden_layer_1_size)\n","    network['b2'] = np.zeros(hidden_layer_2_size)\n","    network['b3'] = np.zeros(output_layer_size)\n","\n","    return network\n","\n","# 順伝播\n","def forward(network, x):\n","    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n","    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n","    hidden_f = functions.sigmoid\n","    \n","    u1 =  np.dot(x, W1) + b1\n","    z1 = hidden_f(u1)\n","    u2 =  np.dot(z1, W2) + b2\n","    z2 = hidden_f(u2)\n","    u3 =  np.dot(z2, W3) + b3\n","    y = functions.softmax(u3)\n"," \n","    return z1, z2, y\n","\n","# 誤差逆伝播\n","def backward(x, d, z1, z2, y):\n","    grad = {}\n","    \n","    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n","    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n","    hidden_d_f = functions.d_sigmoid\n","    last_d_f = functions.d_softmax_with_loss\n","    \n","    \n","    # 出力層でのデルタ\n","    delta3 = last_d_f(d, y)\n","    # b3の勾配\n","    grad['b3'] = np.sum(delta3, axis=0)\n","    # W3の勾配\n","    grad['W3'] = np.dot(z2.T, delta3)\n","    # 2層でのデルタ\n","    delta2 = np.dot(delta3, W3.T) * hidden_d_f(z2)\n","    # b2の勾配\n","    grad['b2'] = np.sum(delta2, axis=0)\n","    # W2の勾配\n","    grad['W2'] = np.dot(z1.T, delta2)\n","    # 1層でのデルタ\n","    delta1 = np.dot(delta2, W2.T) * hidden_d_f(z1)\n","    # b1の勾配\n","    grad['b1'] = np.sum(delta1, axis=0)\n","    # W1の勾配\n","    grad['W1'] = np.dot(x.T, delta1)\n","\n","    return grad\n","\n","# パラメータの初期化\n","network = init_network()\n","\n","accuracies_train = []\n","accuracies_test = []\n","\n","# 正答率\n","def accuracy(x, d):\n","    z1, z2, y = forward(network, x)\n","    y = np.argmax(y, axis=1)\n","    if d.ndim != 1 : d = np.argmax(d, axis=1)\n","    accuracy = np.sum(y == d) / float(x.shape[0])\n","    return accuracy\n","\n","for i in range(iters_num):\n","    # ランダムにバッチを取得    \n","    batch_mask = np.random.choice(train_size, batch_size)\n","    # ミニバッチに対応する教師訓練画像データを取得    \n","    x_batch = x_train[batch_mask]\n","    # ミニバッチに対応する訓練正解ラベルデータを取得する\n","    d_batch = d_train[batch_mask]\n","\n","\n","    \n","    z1, z2, y = forward(network, x_batch)\n","    grad = backward(x_batch, d_batch, z1, z2, y)\n","\n","    if (i+1)%plot_interval==0:\n","        accr_test = accuracy(x_test, d_test)\n","        accuracies_test.append(accr_test)\n","        \n","        accr_train = accuracy(x_batch, d_batch)\n","        accuracies_train.append(accr_train)\n","\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\n","\n","    # パラメータに勾配適用\n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\n","        network[key]  -= learning_rate * grad[key]\n","\n","\n","lists = range(0, iters_num, plot_interval)\n","plt.plot(lists, accuracies_train, label=\"training set\")\n","plt.plot(lists, accuracies_test,  label=\"test set\")\n","plt.legend(loc=\"lower right\")\n","plt.title(\"accuracy\")\n","plt.xlabel(\"count\")\n","plt.ylabel(\"accuracy\")\n","plt.ylim(0, 1.0)\n","# グラフの表示\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eMpi7UPxgeIg","colab_type":"text"},"source":["## ReLU - gauss"]},{"cell_type":"code","metadata":{"id":"0wxFH8SogeIh","colab_type":"code","colab":{}},"source":["import numpy as np\n","from data.mnist import load_mnist\n","from PIL import Image\n","import pickle\n","from common import functions\n","import matplotlib.pyplot as plt\n","\n","# mnistをロード\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n","train_size = len(x_train)\n","\n","print(\"データ読み込み完了\")\n","\n","# 重み初期値補正係数\n","wieght_init = 0.01\n","#入力層サイズ\n","input_layer_size = 784\n","#中間層サイズ\n","hidden_layer_1_size = 40\n","hidden_layer_2_size = 20\n","\n","#出力層サイズ\n","output_layer_size = 10\n","# 繰り返し数\n","iters_num = 2000\n","# ミニバッチサイズ\n","batch_size = 100\n","# 学習率\n","learning_rate = 0.1\n","# 描写頻度\n","plot_interval=10\n","\n","# 初期設定\n","def init_network():\n","    network = {} \n","\n","    network['W1'] = wieght_init * np.random.randn(input_layer_size, hidden_layer_1_size)\n","    network['W2'] = wieght_init * np.random.randn(hidden_layer_1_size, hidden_layer_2_size)\n","    network['W3'] = wieght_init * np.random.randn(hidden_layer_2_size, output_layer_size)\n","            \n","    network['b1'] = np.zeros(hidden_layer_1_size)\n","    network['b2'] = np.zeros(hidden_layer_2_size)\n","    network['b3'] = np.zeros(output_layer_size)\n","\n","    return network\n","\n","# 順伝播\n","def forward(network, x):\n","    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n","    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n","    \n","    ###########  変更箇所  ##############\n","\n","    hidden_f = functions.relu\n","\n","    #################################\n","    \n","    u1 =  np.dot(x, W1) + b1\n","    z1 = hidden_f(u1)\n","    u2 =  np.dot(z1, W2) + b2\n","    z2 = hidden_f(u2)\n","    u3 =  np.dot(z2, W3) + b3\n","    y = functions.softmax(u3)\n"," \n","    return z1, z2, y\n","\n","# 誤差逆伝播\n","def backward(x, d, z1, z2, y):\n","    grad = {}\n","    \n","    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n","    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n","\n","    ###########  変更箇所  ##############\n","    \n","    hidden_d_f = functions.d_relu\n","    \n","    #################################\n","    \n","    \n","    # 出力層でのデルタ\n","    delta3 = functions.d_softmax_with_loss(d, y)\n","    # b3の勾配\n","    grad['b3'] = np.sum(delta3, axis=0)\n","    # W3の勾配\n","    grad['W3'] = np.dot(z2.T, delta3)\n","    # 2層でのデルタ\n","    delta2 = np.dot(delta3, W3.T) * hidden_d_f(z2)\n","    # b2の勾配\n","    grad['b2'] = np.sum(delta2, axis=0)\n","    # W2の勾配\n","    grad['W2'] = np.dot(z1.T, delta2)\n","    # 1層でのデルタ\n","    delta1 = np.dot(delta2, W2.T) * hidden_d_f(z1)\n","    # b1の勾配\n","    grad['b1'] = np.sum(delta1, axis=0)\n","    # W1の勾配\n","    grad['W1'] = np.dot(x.T, delta1)\n","\n","    return grad\n","\n","# パラメータの初期化\n","network = init_network()\n","\n","accuracies_train = []\n","accuracies_test = []\n","\n","# 正答率\n","def accuracy(x, d):\n","    z1, z2, y = forward(network, x)\n","    y = np.argmax(y, axis=1)\n","    if d.ndim != 1 : d = np.argmax(d, axis=1)\n","    accuracy = np.sum(y == d) / float(x.shape[0])\n","    return accuracy\n","\n","for i in range(iters_num):\n","    # ランダムにバッチを取得    \n","    batch_mask = np.random.choice(train_size, batch_size)\n","    # ミニバッチに対応する教師訓練画像データを取得    \n","    x_batch = x_train[batch_mask]\n","    # ミニバッチに対応する訓練正解ラベルデータを取得する\n","    d_batch = d_train[batch_mask]\n","\n","\n","    \n","    z1, z2, y = forward(network, x_batch)\n","    grad = backward(x_batch, d_batch, z1, z2, y)\n","\n","    if (i+1)%plot_interval==0:\n","        accr_test = accuracy(x_test, d_test)\n","        accuracies_test.append(accr_test)\n","        \n","        accr_train = accuracy(x_batch, d_batch)\n","        accuracies_train.append(accr_train)\n","\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\n","        \n","    # パラメータに勾配適用\n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\n","        network[key]  -= learning_rate * grad[key]\n","\n","\n","lists = range(0, iters_num, plot_interval)\n","plt.plot(lists, accuracies_train, label=\"training set\")\n","plt.plot(lists, accuracies_test,  label=\"test set\")\n","plt.legend(loc=\"lower right\")\n","plt.title(\"accuracy\")\n","plt.xlabel(\"count\")\n","plt.ylabel(\"accuracy\")\n","plt.ylim(0, 1.0)\n","# グラフの表示\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TltcZf4tgeIj","colab_type":"text"},"source":["## sigmoid - Xavier"]},{"cell_type":"code","metadata":{"id":"ZOu3JFUtgeIk","colab_type":"code","colab":{}},"source":["import numpy as np\n","from data.mnist import load_mnist\n","from PIL import Image\n","import pickle\n","from common import functions\n","import matplotlib.pyplot as plt\n","\n","# mnistをロード\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n","train_size = len(x_train)\n","\n","print(\"データ読み込み完了\")\n","\n","#入力層サイズ\n","input_layer_size = 784\n","#中間層サイズ\n","hidden_layer_1_size = 40\n","hidden_layer_2_size = 20\n","#出力層サイズ\n","output_layer_size = 10\n","# 繰り返し数\n","iters_num = 2000\n","# ミニバッチサイズ\n","batch_size = 100\n","# 学習率\n","learning_rate = 0.1\n","# 描写頻度\n","plot_interval=10\n","\n","# 初期設定\n","def init_network():\n","    network = {} \n","    \n","    ###########  変更箇所  ##############\n","    \n","    # Xavierの初期値\n","    network['W1'] = np.random.randn(input_layer_size, hidden_layer_1_size) / (np.sqrt(input_layer_size))\n","    network['W2'] = np.random.randn(hidden_layer_1_size, hidden_layer_2_size) / (np.sqrt(hidden_layer_1_size))\n","    network['W3'] = np.random.randn(hidden_layer_2_size, output_layer_size) / (np.sqrt(hidden_layer_2_size))\n","    \n","    #################################\n","    \n","    network['b1'] = np.zeros(hidden_layer_1_size)\n","    network['b2'] = np.zeros(hidden_layer_2_size)\n","    network['b3'] = np.zeros(output_layer_size)\n","\n","    return network\n","\n","# 順伝播\n","def forward(network, x):\n","    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n","    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n","    hidden_f = functions.sigmoid\n","    \n","    u1 =  np.dot(x, W1) + b1\n","    z1 = hidden_f(u1)\n","    u2 =  np.dot(z1, W2) + b2\n","    z2 = hidden_f(u2)\n","    u3 =  np.dot(z2, W3) + b3\n","    y = functions.softmax(u3)\n"," \n","    return z1, z2, y\n","\n","# 誤差逆伝播\n","def backward(x, d, z1, z2, y):\n","    grad = {}\n","    \n","    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n","    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n","    hidden_d_f = functions.d_sigmoid\n","    \n","    # 出力層でのデルタ\n","    delta3 = functions.d_softmax_with_loss(d, y)\n","    # b3の勾配\n","    grad['b3'] = np.sum(delta3, axis=0)\n","    # W3の勾配\n","    grad['W3'] = np.dot(z2.T, delta3)\n","    # 2層でのデルタ\n","    delta2 = np.dot(delta3, W3.T) * hidden_d_f(z2)\n","    # b2の勾配\n","    grad['b2'] = np.sum(delta2, axis=0)\n","    # W2の勾配\n","    grad['W2'] = np.dot(z1.T, delta2)\n","    # 1層でのデルタ\n","    delta1 = np.dot(delta2, W2.T) * hidden_d_f(z1)\n","    # b1の勾配\n","    grad['b1'] = np.sum(delta1, axis=0)\n","    # W1の勾配\n","    grad['W1'] = np.dot(x.T, delta1)\n","\n","    return grad\n","\n","# パラメータの初期化\n","network = init_network()\n","\n","accuracies_train = []\n","accuracies_test = []\n","\n","# 正答率\n","def accuracy(x, d):\n","    z1, z2, y = forward(network, x)\n","    y = np.argmax(y, axis=1)\n","    if d.ndim != 1 : d = np.argmax(d, axis=1)\n","    accuracy = np.sum(y == d) / float(x.shape[0])\n","    return accuracy\n","\n","for i in range(iters_num):\n","    # ランダムにバッチを取得    \n","    batch_mask = np.random.choice(train_size, batch_size)\n","    # ミニバッチに対応する教師訓練画像データを取得    \n","    x_batch = x_train[batch_mask]\n","    # ミニバッチに対応する訓練正解ラベルデータを取得する\n","    d_batch = d_train[batch_mask]\n","\n","\n","    \n","    z1, z2, y = forward(network, x_batch)\n","    grad = backward(x_batch, d_batch, z1, z2, y)\n","\n","    if (i+1)%plot_interval==0:\n","        accr_test = accuracy(x_test, d_test)\n","        accuracies_test.append(accr_test)\n","        \n","        accr_train = accuracy(x_batch, d_batch)\n","        accuracies_train.append(accr_train)\n","\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\n","        \n","    # パラメータに勾配適用\n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\n","        network[key]  -= learning_rate * grad[key]\n","\n","\n","lists = range(0, iters_num, plot_interval)\n","plt.plot(lists, accuracies_train, label=\"training set\")\n","plt.plot(lists, accuracies_test,  label=\"test set\")\n","plt.legend(loc=\"lower right\")\n","plt.title(\"accuracy\")\n","plt.xlabel(\"count\")\n","plt.ylabel(\"accuracy\")\n","plt.ylim(0, 1.0)\n","# グラフの表示\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"18GyO47kgeIm","colab_type":"text"},"source":["## ReLU - He"]},{"cell_type":"code","metadata":{"id":"mR4N3MLWgeIn","colab_type":"code","colab":{}},"source":["import numpy as np\n","from data.mnist import load_mnist\n","from PIL import Image\n","import pickle\n","from common import functions\n","import matplotlib.pyplot as plt\n","\n","# mnistをロード\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n","train_size = len(x_train)\n","\n","print(\"データ読み込み完了\")\n","\n","# 重み初期値補正係数\n","wieght_init = 0.01\n","#入力層サイズ\n","input_layer_size = 784\n","#中間層サイズ\n","hidden_layer_1_size = 40\n","hidden_layer_2_size = 20\n","\n","#出力層サイズ\n","output_layer_size = 10\n","# 繰り返し数\n","iters_num = 2000\n","# ミニバッチサイズ\n","batch_size = 100\n","# 学習率\n","learning_rate = 0.1\n","# 描写頻度\n","plot_interval=10\n","\n","# 初期設定\n","def init_network():\n","    network = {} \n","\n","    ###########  変更箇所  ##############\n","\n","    # Heの初期値\n","    network['W1'] = np.random.randn(input_layer_size, hidden_layer_1_size) / np.sqrt(input_layer_size) * np.sqrt(2)\n","    network['W2'] = np.random.randn(hidden_layer_1_size, hidden_layer_2_size) / np.sqrt(hidden_layer_1_size) * np.sqrt(2)\n","    network['W3'] = np.random.randn(hidden_layer_2_size, output_layer_size) / np.sqrt(hidden_layer_2_size) * np.sqrt(2)\n","        \n","    #################################\n","    \n","    network['b1'] = np.zeros(hidden_layer_1_size)\n","    network['b2'] = np.zeros(hidden_layer_2_size)\n","    network['b3'] = np.zeros(output_layer_size)\n","\n","    return network\n","\n","# 順伝播\n","def forward(network, x):\n","    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n","    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n","\n","    ###########  変更箇所  ##############\n","    \n","    hidden_f = functions.relu\n","    \n","    #################################\n","    \n","    u1 =  np.dot(x, W1) + b1\n","    z1 = hidden_f(u1)\n","    u2 =  np.dot(z1, W2) + b2\n","    z2 = hidden_f(u2)\n","    u3 =  np.dot(z2, W3) + b3\n","    y = functions.softmax(u3)\n"," \n","    return z1, z2, y\n","\n","# 誤差逆伝播\n","def backward(x, d, z1, z2, y):\n","    grad = {}\n","    \n","    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n","    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n","    \n","    ###########  変更箇所  ##############\n","    \n","    hidden_d_f = functions.d_relu\n","    \n","    #################################\n","    \n","    # 出力層でのデルタ\n","    delta3 = functions.d_softmax_with_loss(d, y)\n","    # b3の勾配\n","    grad['b3'] = np.sum(delta3, axis=0)\n","    # W3の勾配\n","    grad['W3'] = np.dot(z2.T, delta3)\n","    # 2層でのデルタ\n","    delta2 = np.dot(delta3, W3.T) * hidden_d_f(z2)\n","    # b2の勾配\n","    grad['b2'] = np.sum(delta2, axis=0)\n","    # W2の勾配\n","    grad['W2'] = np.dot(z1.T, delta2)\n","    # 1層でのデルタ\n","    delta1 = np.dot(delta2, W2.T) * hidden_d_f(z1)\n","    # b1の勾配\n","    grad['b1'] = np.sum(delta1, axis=0)\n","    # W1の勾配\n","    grad['W1'] = np.dot(x.T, delta1)\n","\n","    return grad\n","\n","# パラメータの初期化\n","network = init_network()\n","\n","accuracies_train = []\n","accuracies_test = []\n","\n","# 正答率\n","def accuracy(x, d):\n","    z1, z2, y = forward(network, x)\n","    y = np.argmax(y, axis=1)\n","    if d.ndim != 1 : d = np.argmax(d, axis=1)\n","    accuracy = np.sum(y == d) / float(x.shape[0])\n","    return accuracy\n","\n","for i in range(iters_num):\n","    # ランダムにバッチを取得    \n","    batch_mask = np.random.choice(train_size, batch_size)\n","    # ミニバッチに対応する教師訓練画像データを取得    \n","    x_batch = x_train[batch_mask]\n","    # ミニバッチに対応する訓練正解ラベルデータを取得する\n","    d_batch = d_train[batch_mask]\n","\n","\n","    \n","    z1, z2, y = forward(network, x_batch)\n","    grad = backward(x_batch, d_batch, z1, z2, y)\n","\n","    if (i+1)%plot_interval==0:\n","        accr_test = accuracy(x_test, d_test)\n","        accuracies_test.append(accr_test)\n","        \n","        accr_train = accuracy(x_batch, d_batch)\n","        accuracies_train.append(accr_train)\n","\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\n","        \n","    # パラメータに勾配適用\n","    for key in ('W1', 'W2', 'W3', 'b1', 'b2', 'b3'):\n","        network[key]  -= learning_rate * grad[key]\n","\n","\n","lists = range(0, iters_num, plot_interval)\n","plt.plot(lists, accuracies_train, label=\"training set\")\n","plt.plot(lists, accuracies_test,  label=\"test set\")\n","plt.legend(loc=\"lower right\")\n","plt.title(\"accuracy\")\n","plt.xlabel(\"count\")\n","plt.ylabel(\"accuracy\")\n","plt.ylim(0, 1.0)\n","# グラフの表示\n","plt.show()"],"execution_count":0,"outputs":[]}]}
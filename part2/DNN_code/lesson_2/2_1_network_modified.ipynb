{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"colab":{"name":"2_1_network_modified.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"8cNl2QA_Rnv5","colab_type":"text"},"source":["# 準備"]},{"cell_type":"markdown","metadata":{"id":"YkwjN1jNVAYy","colab_type":"text"},"source":["## Googleドライブのマウント"]},{"cell_type":"code","metadata":{"id":"pvFXpiH3EVC1","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Ub7RYdeY6pK","colab_type":"text"},"source":["## sys.pathの設定"]},{"cell_type":"markdown","metadata":{"id":"oql7L19rEsWi","colab_type":"text"},"source":["以下では，Googleドライブのマイドライブ直下にDNN_codeフォルダを置くことを仮定しています．必要に応じて，パスを変更してください．"]},{"cell_type":"code","metadata":{"id":"7Ic2JzkvFX59","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/DNN_code')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nbefx3-XfBdG","colab_type":"text"},"source":["# network modified"]},{"cell_type":"markdown","metadata":{"id":"kz_WkIp7fBdI","colab_type":"text"},"source":["## layers"]},{"cell_type":"code","metadata":{"id":"N0Ys-3jbfBdJ","colab_type":"code","colab":{}},"source":["import numpy as np\n","from common import layers\n","from collections import OrderedDict\n","from common import functions\n","from data.mnist import load_mnist\n","import matplotlib.pyplot as plt\n","\n","\n","# ReLU layer\n","class Relu:\n","    def __init__(self):\n","        self.mask = None\n","\n","    def forward(self, x):\n","        # mask.shape = x.shape\n","        # True or Falseを要素として持つ\n","        self.mask = (x <= 0)\n","        out = x.copy()\n","        # Trueの箇所を0にする\n","        out[self.mask] = 0\n","\n","        return out\n","\n","    def backward(self, dout):\n","        # Trueの箇所を0にする\n","        dout[self.mask] = 0\n","        dx = dout\n","\n","        return dx\n","    \n","# Affine layer(全結合 layer)\n","class Affine:\n","    \n","    def __init__(self, W, b):\n","        self.W =W\n","        self.b = b\n","        \n","        self.x = None\n","        self.original_x_shape = None\n","        # 重み・バイアスパラメータの微分\n","        self.dW = None\n","        self.db = None\n","\n","    def forward(self, x):\n","        out = np.dot(self.x, self.W) + self.b\n","        \n","        return out\n","\n","    def backward(self, dout):\n","        dx = np.dot(dout, self.W.T)\n","        self.dW = np.dot(self.x.T, dout)\n","        self.db = np.sum(dout, axis=0)\n","\n","        return dx\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yuoKoWYRfBdM","colab_type":"text"},"source":["## two layer network class"]},{"cell_type":"code","metadata":{"id":"pfwidLypfBdN","colab_type":"code","colab":{}},"source":["class TwoLayerNet:\n","    '''\n","    input_size: 入力層のノード数\n","    hidden_size: 隠れ層のノード数\n","    output_size: 出力層のノード数\n","    weight_init_std: 重みの初期化方法\n","    '''\n","    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n","        # 重みの初期化\n","        self.params = {}\n","        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n","        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n","        self.params['b1'] = np.zeros(hidden_size)\n","        self.params['b2'] = np.zeros(output_size)\n","\n","        # レイヤの生成\n","        self.layers = OrderedDict()\n","        self.layers['Affine1'] = layers.Affine(self.params['W1'], self.params['b1'])\n","        self.layers['Relu1'] = layers.Relu()\n","        self.layers['Affine2'] = layers.Affine(self.params['W2'], self.params['b2'])\n","        \n","        self.lastLayer = layers.SoftmaxWithLoss()\n","        \n","    # 順伝播\n","    def predict(self, x):\n","        for layer in self.layers.values():\n","            x = layer.forward(x)\n","        \n","        return x\n","        \n","    # 誤差\n","    def loss(self, x, d):\n","        y = self.predict(x)\n","        return self.lastLayer.forward(y, d)\n","    \n","    # 精度\n","    def accuracy(self, x, d):\n","        y = self.predict(x)\n","        y = np.argmax(y, axis=1)\n","        if d.ndim != 1 : d = np.argmax(d, axis=1)\n","        \n","        accuracy = np.sum(y == d) / float(x.shape[0])\n","        return accuracy\n","             \n","    # 勾配\n","    def gradient(self, x, d):\n","        # forward\n","\n","        self.loss(x, d)\n","\n","        # backward\n","        dout = 1\n","        dout = self.lastLayer.backward(dout)\n","\n","        layers = list(self.layers.values())\n","        layers.reverse()\n","        for layer in layers:\n","            dout = layer.backward(dout)\n","\n","        # 設定\n","        grad = {}\n","        grad['W1'], grad['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n","        grad['W2'], grad['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n","\n","        return grad\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NdQWNAZufBdQ","colab_type":"text"},"source":["## 1_4_1_mnist_sample modified"]},{"cell_type":"code","metadata":{"id":"uQNVEwd6fBdQ","colab_type":"code","colab":{}},"source":["# データの読み込み\n","(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n","\n","print(\"データ読み込み完了\")\n","\n","network = TwoLayerNet(input_size=784, hidden_size=40, output_size=10)\n","\n","iters_num = 1000\n","train_size = x_train.shape[0]\n","batch_size = 100\n","learning_rate = 0.1\n","\n","train_loss_list = []\n","accuracies_train = []\n","accuracies_test = []\n","\n","plot_interval=10\n","\n","for i in range(iters_num):\n","    batch_mask = np.random.choice(train_size, batch_size)\n","    x_batch = x_train[batch_mask]\n","    d_batch = d_train[batch_mask]\n","\n","    # 勾配\n","    grad = network.gradient(x_batch, d_batch)\n","    \n","    for key in ('W1', 'W2', 'b1', 'b2'):\n","        network.params[key] -= learning_rate * grad[key]\n","    \n","    loss = network.loss(x_batch, d_batch)\n","    train_loss_list.append(loss)\n","    \n","    if (i + 1) % plot_interval == 0:\n","        accr_test = network.accuracy(x_test, d_test)\n","        accuracies_test.append(accr_test)        \n","        accr_train = network.accuracy(x_batch, d_batch)\n","        accuracies_train.append(accr_train)\n","\n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\n","        \n","\n","lists = range(0, iters_num, plot_interval)\n","plt.plot(lists, accuracies_train, label=\"training set\")\n","plt.plot(lists, accuracies_test,  label=\"test set\")\n","plt.legend(loc=\"lower right\")\n","plt.title(\"accuracy\")\n","plt.xlabel(\"count\")\n","plt.ylabel(\"accuracy\")\n","plt.ylim(0, 1.0)\n","# グラフの表示\n","plt.show()"],"execution_count":0,"outputs":[]}]}